(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[869],{5671:function(e,n,t){"use strict";t.d(n,{Tl:function(){return f},hu:function(){return l}});var r=t(5893),i=t(9008),a=t.n(i),s=t(1163),o=t(7294),u=t(9147),c=t.n(u);t(7319);let d=e=>{let n=(0,o.useRef)(null),i=(0,o.useRef)(null),u=(0,o.useMemo)(()=>e.sources.map(e=>{let{name:n,contents:i}=e;return{name:n,...function(e){let n;let i=null;{i=document.createElement("div");let a=t(4631);n=a(i,{lineNumbers:!0,lineWrapping:!0,theme:"monokai",readOnly:!0})}return{Container:function(t){return(0,r.jsx)("div",{...t,children:(0,r.jsx)("div",{ref(t){i&&t&&(t.appendChild(i),n.setOption("value",e))}})})}}}(i)}}),e.sources),d=(0,o.useRef)(null),f=(0,o.useMemo)(()=>{if(e.gui){let n=t(4376),r=new n.GUI({autoPlace:!1});return r.domElement.style.position="relative",r.domElement.style.zIndex="1000",r}},[]),l=(0,o.useRef)(null),p=(0,o.useMemo)(()=>{if(e.stats){let n=t(2792);return new n}},[]),m=(0,s.useRouter)(),h=m.asPath.match(/#([a-zA-Z0-9\.\/]+)/),[g,b]=(0,o.useState)(null),[y,v]=(0,o.useState)(null);return(0,o.useEffect)(()=>{if(h?v(h[1]):v(u[0].name),f&&d.current)for(d.current.appendChild(f.domElement);f.__controllers.length>0;)f.__controllers[0].remove();p&&l.current&&(p.dom.style.position="absolute",p.showPanel(1),l.current.appendChild(p.dom));let t={active:!0},r=()=>{t.active=!1};try{let i=n.current;if(!i)throw Error("The canvas is not available");let a=e.init({canvas:i,pageState:t,gui:f,stats:p});a instanceof Promise&&a.catch(e=>{console.error(e),b(e)})}catch(s){console.error(s),b(s)}return r},[]),(0,r.jsxs)("main",{children:[(0,r.jsxs)(a(),{children:[(0,r.jsx)("style",{dangerouslySetInnerHTML:{__html:"\n            .CodeMirror {\n              height: auto !important;\n              margin: 1em 0;\n            }\n\n            .CodeMirror-scroll {\n              height: auto !important;\n              overflow: visible !important;\n            }\n          "}}),(0,r.jsx)("title",{children:"".concat(e.name," - WebGPU Samples")}),(0,r.jsx)("meta",{name:"description",content:e.description}),(0,r.jsx)("meta",{httpEquiv:"origin-trial",content:e.originTrial})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h1",{children:e.name}),(0,r.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/".concat("webgpu/webgpu-samples","/tree/main/").concat(e.filename),children:"See it on Github!"}),(0,r.jsx)("p",{children:e.description}),g?(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("p",{children:"Something went wrong. Do your browser and device support WebGPU?"}),(0,r.jsx)("p",{children:"".concat(g)})]}):null]}),(0,r.jsxs)("div",{className:c().canvasContainer,children:[(0,r.jsx)("div",{style:{position:"absolute",left:10},ref:l}),(0,r.jsx)("div",{style:{position:"absolute",right:10},ref:d}),(0,r.jsx)("canvas",{ref:n})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("nav",{className:c().sourceFileNav,ref:i,children:(0,r.jsx)("div",{className:c().sourceFileScrollContainer,onScroll(e){let n=e.currentTarget,t=n.scrollWidth-n.clientWidth-n.scrollLeft;n.scrollLeft>25?i.current.setAttribute("data-left","true"):i.current.setAttribute("data-left","false"),t>25?i.current.setAttribute("data-right","true"):i.current.setAttribute("data-right","false")},children:(0,r.jsx)("ul",{children:u.map((e,n)=>(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"#".concat(e.name),"data-active":y==e.name,onClick(){v(e.name)},children:e.name})},n))})})}),u.map((e,n)=>(0,r.jsx)(e.Container,{className:c().sourceFileContainer,"data-active":y==e.name},n))]})]})},f=e=>(0,r.jsx)(d,{...e});function l(e,n){if(!e)throw Error(n)}},7606:function(e,n,t){"use strict";t.d(n,{NJ:function(){return s},Ot:function(){return a},a1:function(){return i}});var r=t(134);let i=(e,n,t,r,i,a,s)=>{let o=[];for(let u=0;u<e.length;u++)o.push({binding:e[u],visibility:n[u%n.length],[t[u]]:r[u]});let c=s.createBindGroupLayout({label:"".concat(a,".bindGroupLayout"),entries:o}),d=[];for(let f=0;f<i.length;f++){let l=[];for(let p=0;p<i[0].length;p++)l.push({binding:p,resource:i[f][p]});let m=s.createBindGroup({label:"".concat(a,".bindGroup").concat(f),layout:c,entries:l});d.push(m)}return{bindGroups:d,bindGroupLayout:c}},a=async e=>{let n=async n=>{let t,{canvas:r,pageState:i,gui:a,stats:s}=n,o=await navigator.gpu.requestAdapter(),u=o.features.has("timestamp-query");if(t=u?await o.requestDevice({requiredFeatures:["timestamp-query"]}):await o.requestDevice(),!i.active)return;let c=r.getContext("webgpu"),d=window.devicePixelRatio;r.width=r.clientWidth*d,r.height=r.clientHeight*d;let f=navigator.gpu.getPreferredCanvasFormat();c.configure({device:t,format:f,alphaMode:"premultiplied"}),e({canvas:r,pageState:i,gui:a,device:t,context:c,presentationFormat:f,stats:s,timestampQueryAvailable:u})};return n};class s{executeRun(e,n,t,r){let i=e.beginRenderPass(n);i.setPipeline(t);for(let a=0;a<r.length;a++)i.setBindGroup(a,r[a]);i.draw(6,1,0,0),i.end()}setUniformArguments(e,n,t,r){for(let i=0;i<r.length;i++)e.queue.writeBuffer(n,4*i,new Float32Array([t[r[i]]]))}create2DRenderPipeline(e,n,t,i,a){return e.createRenderPipeline({label:"".concat(n,".pipeline"),layout:e.createPipelineLayout({bindGroupLayouts:t}),vertex:{module:e.createShaderModule({code:r.Z}),entryPoint:"vert_main"},fragment:{module:e.createShaderModule({code:i}),entryPoint:"frag_main",targets:[{format:a}]},primitive:{topology:"triangle-list",cullMode:"none"}})}}},6869:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return z}});var r,i,a,s,o,u,c,d,f,l,p=t(5671),m=t(6416);(r=u||(u={}))[r.POINTS=0]="POINTS",r[r.LINE=1]="LINE",r[r.LINE_LOOP=2]="LINE_LOOP",r[r.LINE_STRIP=3]="LINE_STRIP",r[r.TRIANGLES=4]="TRIANGLES",r[r.TRIANGLE_STRIP=5]="TRIANGLE_STRIP",r[r.TRIANGLE_FAN=6]="TRIANGLE_FAN",(i=c||(c={}))[i.BYTE=5120]="BYTE",i[i.UNSIGNED_BYTE=5121]="UNSIGNED_BYTE",i[i.SHORT=5122]="SHORT",i[i.UNSIGNED_SHORT=5123]="UNSIGNED_SHORT",i[i.INT=5124]="INT",i[i.UNSIGNED_INT=5125]="UNSIGNED_INT",i[i.FLOAT=5126]="FLOAT",i[i.DOUBLE=5130]="DOUBLE",(a=d||(d={}))[a.SCALAR=0]="SCALAR",a[a.VEC2=1]="VEC2",a[a.VEC3=2]="VEC3",a[a.VEC4=3]="VEC4",a[a.MAT2=4]="MAT2",a[a.MAT3=5]="MAT3",a[a.MAT4=6]="MAT4";let h=(e,n)=>Math.floor((e+n-1)/n)*n,g=e=>{switch(e){case"SCALAR":return d.SCALAR;case"VEC2":return d.VEC2;case"VEC3":return d.VEC3;case"VEC4":return d.VEC4;case"MAT2":return d.MAT2;case"MAT3":return d.MAT3;case"MAT4":return d.MAT4;default:throw Error("Unhandled glTF Type ".concat(e))}},b=e=>{switch(e){case d.SCALAR:return 1;case d.VEC2:return 2;case d.VEC3:return 3;case d.VEC4:case d.MAT2:return 4;case d.MAT3:return 9;case d.MAT4:return 16;default:throw Error("Invalid glTF Type ".concat(e))}},y=(e,n)=>{let t=null;switch(e){case c.BYTE:t="sint8";break;case c.UNSIGNED_BYTE:t="uint8";break;case c.SHORT:t="sint16";break;case c.UNSIGNED_SHORT:t="uint16";break;case c.INT:t="int32";break;case c.UNSIGNED_INT:t="uint32";break;case c.FLOAT:t="float32";break;default:throw Error("Unrecognized or unsupported glTF type ".concat(e))}switch(b(n)){case 1:return t;case 2:return t+"x2";case 3:return t+"x3";case 4:return t+"x4";default:throw Error("Invalid number of components for gltfType: ".concat(n))}},v=(e,n)=>{let t=0;switch(e){case c.BYTE:case c.UNSIGNED_BYTE:t=1;break;case c.SHORT:case c.UNSIGNED_SHORT:t=2;break;case c.INT:case c.UNSIGNED_INT:case c.FLOAT:t=4;break;case c.DOUBLE:t=8;break;default:throw Error("Unrecognized GLTF Component Type?")}return b(n)*t},T=e=>{switch(e){case"float32":default:return"f32";case"float32x2":return"vec2<f32>";case"float32x3":return"vec3<f32>";case"float32x4":return"vec4<f32>";case"uint32":return"u32";case"uint32x2":case"uint8x2":case"uint16x2":return"vec2<u32>";case"uint32x3":return"vec3<u32>";case"uint32x4":case"uint8x4":case"uint16x4":return"vec4<u32>"}};class G{constructor(e,n,t){this.buffer=new Uint8Array(e,n,t)}}class w{addUsage(e){this.usage=this.usage|e}upload(e){let n=e.createBuffer({size:h(this.view.byteLength,4),usage:this.usage,mappedAtCreation:!0});new Uint8Array(n.getMappedRange()).set(this.view),n.unmap(),this.gpuBuffer=n,this.needsUpload=!1}constructor(e,n){this.byteLength=n.byteLength,this.byteStride=0,void 0!==n.byteStride&&(this.byteStride=n.byteStride);let t=0;void 0!==n.byteOffset&&(t=n.byteOffset),this.view=e.buffer.subarray(t,t+this.byteLength),this.needsUpload=!1,this.gpuBuffer=null,this.usage=0}}class x{get byteStride(){let e=v(this.componentType,this.structureType);return Math.max(e,this.view.byteStride)}get byteLength(){return this.count*this.byteStride}get vertexType(){return y(this.componentType,this.structureType)}constructor(e,n){this.count=n.count,this.componentType=n.componentType,this.structureType=g(n.type),this.view=e,this.byteOffset=0,void 0!==n.byteOffset&&(this.byteOffset=n.byteOffset)}}class S{buildRenderPipeline(e,n,t,r,i,a,s){let o="struct VertexInput {\n",c=this.attributes.map((e,n)=>{let t=this.attributeMap[e].vertexType,r=e.toLowerCase().replace(/_0$/,"");return o+="	@location(".concat(n,") ").concat(r,": ").concat(T(t),",\n"),{arrayStride:this.attributeMap[e].byteStride,attributes:[{format:this.attributeMap[e].vertexType,offset:this.attributeMap[e].byteOffset,shaderLocation:n}]}});o+="}";let d={module:e.createShaderModule({code:o+n}),entryPoint:"vertexMain",buffers:c},f={module:e.createShaderModule({code:o+t}),entryPoint:"fragmentMain",targets:[{format:r}]},l={topology:"triangle-list"};this.topology==u.TRIANGLE_STRIP&&(l.topology="triangle-strip",l.stripIndexFormat=this.attributeMap.INDICES.vertexType);let p=e.createPipelineLayout({bindGroupLayouts:a,label:"".concat(s,".pipelineLayout")});this.renderPipeline=e.createRenderPipeline({layout:p,label:"".concat(s,".pipeline"),vertex:d,fragment:f,primitive:l,depthStencil:{format:i,depthWriteEnabled:!0,depthCompare:"less"}})}render(e,n){e.setPipeline(this.renderPipeline),n.forEach((n,t)=>{e.setBindGroup(t,n)}),this.attributes.map((n,t)=>{e.setVertexBuffer(t,this.attributeMap[n].view.gpuBuffer,this.attributeMap[n].byteOffset,this.attributeMap[n].byteLength)}),this.attributeMap.INDICES?(e.setIndexBuffer(this.attributeMap.INDICES.view.gpuBuffer,this.attributeMap.INDICES.vertexType,this.attributeMap.INDICES.byteOffset,this.attributeMap.INDICES.byteLength),e.drawIndexed(this.attributeMap.INDICES.count)):e.draw(this.attributeMap.POSITION.count)}constructor(e,n,t){for(let r in this.attributes=[],this.topology=e,this.renderPipeline=null,this.attributeMap=n,this.attributes=t,this.attributeMap){if(this.attributeMap[r].view.needsUpload=!0,"INDICES"===r){this.attributeMap.INDICES.view.addUsage(GPUBufferUsage.INDEX);continue}this.attributeMap[r].view.addUsage(GPUBufferUsage.VERTEX)}}}class B{buildRenderPipeline(e,n,t,r,i,a){for(let s=0;s<this.primitives.length;++s)this.primitives[s].buildRenderPipeline(e,n,t,r,i,a,"PrimitivePipeline".concat(s))}render(e,n){for(let t=0;t<this.primitives.length;++t)this.primitives[t].render(e,n)}constructor(e,n){this.name=e,this.primitives=n}}let E=e=>{if(1179937895!=e.getUint32(0,!0))throw Error("Provided file is not a glB file");if(2!=e.getUint32(4,!0))throw Error("Provided file is glTF 2.0 file")},M=e=>{if(5130562!=e[1])throw Error("Invalid glB: The second chunk of the glB file is not a binary chunk!")};class U{getMatrix(){let e=m._E.identity();m._E.scale(e,this.scale,e);let n=m._E.fromQuat(this.rotation);return m._E.multiply(n,e,e),m._E.translate(e,this.position,e),e}constructor(e=[0,0,0],n=[0,0,0,1],t=[1,1,1]){this.position=e,this.rotation=n,this.scale=t}}class L{setParent(e){this.parent&&(this.parent.removeChild(this),this.parent=null),e.addChild(this),this.parent=e}updateWorldMatrix(e,n){this.localMatrix=this.source.getMatrix(),n?m._E.multiply(n,this.localMatrix,this.worldMatrix):m._E.copy(this.localMatrix,this.worldMatrix);let t=this.worldMatrix;for(let r of(e.queue.writeBuffer(this.nodeTransformGPUBuffer,0,t.buffer,t.byteOffset,t.byteLength),this.children))r.updateWorldMatrix(e,t)}traverse(e){for(let n of(e(this),this.children))n.traverse(e)}renderDrawables(e,n){if(void 0!==this.drawables)for(let t of this.drawables)this.skin?t.render(e,[...n,this.nodeTransformBindGroup,this.skin.skinBindGroup]):t.render(e,[...n,this.nodeTransformBindGroup]);for(let r of this.children)r.renderDrawables(e,n)}addChild(e){this.children.push(e)}removeChild(e){let n=this.children.indexOf(e);this.children.splice(n,1)}constructor(e,n,t,r,i){this.test=0,this.name=r||"node_".concat(t.position," ").concat(t.rotation," ").concat(t.scale),this.source=t,this.parent=null,this.children=[],this.localMatrix=m._E.identity(),this.worldMatrix=m._E.identity(),this.drawables=[],this.nodeTransformGPUBuffer=e.createBuffer({size:16*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),this.nodeTransformBindGroup=e.createBindGroup({layout:n,entries:[{binding:0,resource:{buffer:this.nodeTransformGPUBuffer}}]}),this.skin=i}}class P{constructor(e,n,t){this.nodes=t.nodes,this.name=t.name,this.root=new L(e,n,new U,t.name)}}class C{static createSharedBindGroupLayout(e){this.skinBindGroupLayout=e.createBindGroupLayout({label:"StaticGLTFSkin.bindGroupLayout",entries:[{binding:0,buffer:{type:"read-only-storage"},visibility:GPUShaderStage.VERTEX},{binding:1,buffer:{type:"read-only-storage"},visibility:GPUShaderStage.VERTEX}]})}update(e,n,t){let r=m._E.inverse(t[n].worldMatrix);for(let i=0;i<this.joints.length;i++){let a=this.joints[i],s=m._E.identity();m._E.multiply(r,t[a].worldMatrix,s),e.queue.writeBuffer(this.jointMatricesUniformBuffer,64*i,s.buffer,s.byteOffset,s.byteLength)}}constructor(e,n,t){if(n.componentType!==c.FLOAT||64!==n.byteStride)throw Error("This skin's provided accessor does not access a mat4x4<f32> matrix, or does not access the provided mat4x4<f32> data correctly");this.inverseBindMatrices=new Float32Array(n.view.view.buffer,n.view.view.byteOffset,n.view.view.byteLength/4),this.joints=t;let r={size:16*Float32Array.BYTES_PER_ELEMENT*t.length,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_DST};this.jointMatricesUniformBuffer=e.createBuffer(r),this.inverseBindMatricesUniformBuffer=e.createBuffer(r),e.queue.writeBuffer(this.inverseBindMatricesUniformBuffer,0,this.inverseBindMatrices),this.skinBindGroup=e.createBindGroup({layout:C.skinBindGroupLayout,label:"StaticGLTFSkin.bindGroup",entries:[{binding:0,resource:{buffer:this.jointMatricesUniformBuffer}},{binding:1,resource:{buffer:this.inverseBindMatricesUniformBuffer}}]})}}let I=async(e,n)=>{var t,r,i,a,s;let o=new DataView(e,0,20);E(o);let c=o.getUint32(12,!0),d=JSON.parse(new TextDecoder("utf-8").decode(new Uint8Array(e,20,c)));console.log(d);let f=new Uint32Array(e,20+c,2);M(f);let l=new G(e,28+c,f[0]);for(let p of d.accessors)p.byteOffset=null!==(t=p.byteOffset)&&void 0!==t?t:0,p.normalized=null!==(r=p.normalized)&&void 0!==r&&r;for(let m of d.bufferViews)m.byteOffset=null!==(i=m.byteOffset)&&void 0!==i?i:0;if(d.samplers)for(let h of d.samplers)h.wrapS=null!==(a=h.wrapS)&&void 0!==a?a:10497,h.wrapT=null!==(s=h.wrapT)&&void 0!==s?s:10947;for(let g of d.meshes)for(let b of g.primitives){if("indices"in b){let y=d.accessors[b.indices];d.accessors[b.indices].bufferViewUsage|=GPUBufferUsage.INDEX,d.bufferViews[y.bufferView].usage|=GPUBufferUsage.INDEX}for(let v of Object.values(b.attributes)){let T=d.accessors[v];d.accessors[v].bufferViewUsage|=GPUBufferUsage.VERTEX,d.bufferViews[T.bufferView].usage|=GPUBufferUsage.VERTEX}}let I=[];for(let k=0;k<d.bufferViews.length;++k)I.push(new w(l,d.bufferViews[k]));let A=[];for(let N=0;N<d.accessors.length;++N){let j=d.accessors[N],_=j.bufferView;A.push(new x(I[_],j))}let F=[];for(let R=0;R<d.meshes.length;R++){let O=d.meshes[R],V=[];for(let D=0;D<O.primitives.length;++D){let q=O.primitives[D],W=q.mode;if(void 0===W&&(W=u.TRIANGLES),W!=u.TRIANGLES&&W!=u.TRIANGLE_STRIP)throw Error("Unsupported primitive mode ".concat(q.mode));let Y={},z=[];if(void 0!==d.accessors[q.indices]){let X=A[q.indices];Y.INDICES=X}for(let H in q.attributes){let Z=A[q.attributes[H]];if(Y[H]=Z,Z.structureType>3)throw Error("Vertex attribute accessor accessed an unsupported data type for vertex attribute");z.push(H)}V.push(new S(W,Y,z))}F.push(new B(O.name,V))}let J=[];for(let $ of d.skins){let Q=A[$.inverseBindMatrices];Q.view.addUsage(GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST),Q.view.needsUpload=!0}for(let K=0;K<I.length;++K)I[K].needsUpload&&I[K].upload(n);for(let ee of(C.createSharedBindGroupLayout(n),d.skins)){let en=A[ee.inverseBindMatrices],et=ee.joints;J.push(new C(n,en,et))}let er=[],ei=n.createBindGroupLayout({label:"NodeUniforms.bindGroupLayout",entries:[{binding:0,buffer:{type:"uniform"},visibility:GPUShaderStage.VERTEX}]});for(let ea of d.nodes){let es=new U(ea.translation,ea.rotation,ea.scale),eo=new L(n,ei,es,ea.name,J[ea.skin]),eu=F[ea.mesh];eu&&eo.drawables.push(eu),er.push(eo)}er.forEach((e,n)=>{let t=d.nodes[n].children;t&&t.forEach(n=>{let t=er[n];t.setParent(e)})});let ec=[];for(let ed of d.scenes){let ef=new P(n,ei,ed),el=ef.nodes;el.forEach(e=>{let n=er[e];n.setParent(ef.root)}),ec.push(ef)}return{meshes:F,nodes:er,scenes:ec,skins:J}};var k="// Whale.glb Vertex attributes\n// Read in VertexInput from attributes\n// f32x3    f32x3   f32x2       u8x4       f32x4\nstruct VertexOutput {\n  @builtin(position) Position: vec4<f32>,\n  @location(0) normal: vec3<f32>,\n  @location(1) joints: vec4<f32>,\n  @location(2) weights: vec4<f32>,\n}\n\nstruct CameraUniforms {\n  proj_matrix: mat4x4f,\n  view_matrix: mat4x4f,\n  model_matrix: mat4x4f,\n}\n\nstruct GeneralUniforms {\n  render_mode: u32,\n  skin_mode: u32,\n}\n\nstruct NodeUniforms {\n  world_matrix: mat4x4f,\n}\n\n@group(0) @binding(0) var<uniform> camera_uniforms: CameraUniforms;\n@group(1) @binding(0) var<uniform> general_uniforms: GeneralUniforms;\n@group(2) @binding(0) var<uniform> node_uniforms: NodeUniforms;\n@group(3) @binding(0) var<storage, read> joint_matrices: array<mat4x4<f32>>;\n@group(3) @binding(1) var<storage, read> inverse_bind_matrices: array<mat4x4<f32>>;\n\n@vertex\nfn vertexMain(input: VertexInput) -> VertexOutput {\n  var output: VertexOutput;\n  // Compute joint_matrices * inverse_bind_matrices\n  let joint0 = joint_matrices[input.joints[0]] * inverse_bind_matrices[input.joints[0]];\n  let joint1 = joint_matrices[input.joints[1]] * inverse_bind_matrices[input.joints[1]];\n  let joint2 = joint_matrices[input.joints[2]] * inverse_bind_matrices[input.joints[2]];\n  let joint3 = joint_matrices[input.joints[3]] * inverse_bind_matrices[input.joints[3]];\n  // Compute influence of joint based on weight\n  let skin_matrix = \n    joint0 * input.weights[0] +\n    joint1 * input.weights[1] +\n    joint2 * input.weights[2] +\n    joint3 * input.weights[3];\n  // Position of the vertex relative to our world\n  let world_position = vec4<f32>(input.position.x, input.position.y, input.position.z, 1.0);\n  // Vertex position with model rotation, skinning, and the mesh's node transformation applied.\n  let skinned_position = camera_uniforms.model_matrix * skin_matrix * node_uniforms.world_matrix * world_position;\n  // Vertex position with only the model rotation applied.\n  let rotated_position = camera_uniforms.model_matrix * world_position;\n  // Determine which position to used based on whether skinMode is turnd on or off.\n  let transformed_position = select(\n    rotated_position,\n    skinned_position,\n    general_uniforms.skin_mode == 0\n  );\n  // Apply the camera and projection matrix transformations to our transformed position;\n  output.Position = camera_uniforms.proj_matrix * camera_uniforms.view_matrix * transformed_position;\n  output.normal = input.normal;\n  // Convert u32 joint data to f32s to prevent flat interpolation error.\n  output.joints = vec4<f32>(f32(input.joints[0]), f32(input.joints[1]), f32(input.joints[2]), f32(input.joints[3]));\n  output.weights = input.weights;\n  return output;\n}\n\n@fragment\nfn fragmentMain(input: VertexOutput) -> @location(0) vec4<f32> {\n  switch general_uniforms.render_mode {\n    case 1: {\n      return input.joints;\n    } \n    case 2: {\n      return input.weights;\n    }\n    default: {\n      return vec4<f32>(input.normal, 1.0);\n    }\n  }\n}",A=t(2624),N=t(7606);let j=new Float32Array([0,1,0,-1,2,1,2,-1,4,1,4,-1,6,1,6,-1,8,1,8,-1,10,1,10,-1,12,1,12,-1]),_=new Uint32Array([0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,1,0,0,0,1,2,0,0,1,2,0,0,2,0,0,0,2,0,0,0,1,2,3,0,1,2,3,0,2,3,0,0,2,3,0,0]),F=new Float32Array([1,0,0,0,1,0,0,0,.5,.5,0,0,.5,.5,0,0,1,0,0,0,1,0,0,0,.5,.5,0,0,.5,.5,0,0,1,0,0,0,1,0,0,0,.5,.5,0,0,.5,.5,0,0,1,0,0,0,1,0,0,0]),R=new Uint16Array([0,1,0,2,1,3,2,3,2,4,3,5,4,5,4,6,5,7,6,7,6,8,7,9,8,9,8,10,9,11,10,11,10,12,11,13,12,13]),O=e=>{let n=(n,t)=>{let r=e.createBuffer({size:n.byteLength,usage:GPUBufferUsage.VERTEX,mappedAtCreation:!0});return"f32"===t?new Float32Array(r.getMappedRange()).set(n):new Uint32Array(r.getMappedRange()).set(n),r.unmap(),r},t=n(j,"f32"),r=n(_,"u32"),i=n(F,"f32"),a=e.createBuffer({size:Uint16Array.BYTES_PER_ELEMENT*R.length,usage:GPUBufferUsage.INDEX,mappedAtCreation:!0});return new Uint16Array(a.getMappedRange()).set(R),a.unmap(),{positions:t,joints:r,weights:i,indices:a}},V=(e,n,t,r,i)=>{let a=e.createRenderPipeline({label:"SkinnedGridRenderer",layout:e.createPipelineLayout({label:"SkinnedGridRenderer.pipelineLayout",bindGroupLayouts:i}),vertex:{module:e.createShaderModule({label:"SkinnedGridRenderer.vertexShader",code:t}),entryPoint:"vertexMain",buffers:[{arrayStride:2*Float32Array.BYTES_PER_ELEMENT,attributes:[{format:"float32x2",offset:0,shaderLocation:0}]},{arrayStride:4*Uint32Array.BYTES_PER_ELEMENT,attributes:[{format:"uint32x4",offset:0,shaderLocation:1}]},{arrayStride:4*Float32Array.BYTES_PER_ELEMENT,attributes:[{format:"float32x4",offset:0,shaderLocation:2}]}]},fragment:{module:e.createShaderModule({label:"SkinnedGridRenderer.fragmentShader",code:r}),entryPoint:"fragmentMain",targets:[{format:n}]},primitive:{topology:"line-list"}});return a};var D="src/sample/skinnedMesh/main.ts";(s=f||(f={}))[s.NORMAL=0]="NORMAL",s[s.JOINTS=1]="JOINTS",s[s.WEIGHTS=2]="WEIGHTS",(o=l||(l={}))[o.ON=0]="ON",o[o.OFF=1]="OFF";let q=e=>{let n=[0,0,0,0],t=m._E.getScaling(e),r=1/t[0],i=1/t[1],a=1/t[2],s=e[0]*r,o=e[1]*i,u=e[2]*a,c=e[4]*r,d=e[5]*i,f=e[6]*a,l=e[8]*r,p=e[9]*i,h=e[10]*a,g=s+d+h,b=0;return g>0?(b=2*Math.sqrt(g+1),n[3]=.25*b,n[0]=(f-p)/b,n[1]=(l-u)/b,n[2]=(o-c)/b):s>d&&s>h?(b=2*Math.sqrt(1+s-d-h),n[3]=(f-p)/b,n[0]=.25*b,n[1]=(o+c)/b,n[2]=(l+u)/b):d>h?(b=2*Math.sqrt(1+d-s-h),n[3]=(l-u)/b,n[0]=(o+c)/b,n[1]=.25*b,n[2]=(f+p)/b):(b=2*Math.sqrt(1+h-s-d),n[3]=(o-c)/b,n[0]=(l+u)/b,n[1]=(f+p)/b,n[2]=.25*b),n},W=async e=>{let{canvas:n,pageState:t,gui:r}=e,i=await navigator.gpu.requestAdapter(),a=await i.requestDevice();if(!t.active)return;let s=n.getContext("webgpu"),o=window.devicePixelRatio||1;n.width=n.clientWidth*o,n.height=n.clientHeight*o;let u=navigator.gpu.getPreferredCanvasFormat();s.configure({device:a,format:u,alphaMode:"premultiplied"});let c={cameraX:0,cameraY:-5.1,cameraZ:-14.6,objectScale:1,angle:.2,speed:50,object:"Whale",renderMode:"NORMAL",skinMode:"ON"};r.add(c,"object",["Whale","Skinned Grid"]).onChange(()=>{"Skinned Grid"===c.object?(c.cameraX=-10,c.cameraY=0,c.objectScale=1.27):"OFF"===c.skinMode?(c.cameraX=0,c.cameraY=0,c.cameraZ=-11):(c.cameraX=0,c.cameraY=-5.1,c.cameraZ=-14.6)}),r.add(c,"renderMode",["NORMAL","JOINTS","WEIGHTS"]).onChange(()=>{a.queue.writeBuffer(b,0,new Uint32Array([f[c.renderMode]]))}),r.add(c,"skinMode",["ON","OFF"]).onChange(()=>{"Whale"===c.object&&("OFF"===c.skinMode?(c.cameraX=0,c.cameraY=0,c.cameraZ=-11):(c.cameraX=0,c.cameraY=-5.1,c.cameraZ=-14.6)),a.queue.writeBuffer(b,4,new Uint32Array([l[c.skinMode]]))});let d=r.addFolder("Animation Settings");d.add(c,"angle",.05,.5).step(.05),d.add(c,"speed",10,100).step(10);let p=a.createTexture({size:[n.width,n.height],format:"depth24plus",usage:GPUTextureUsage.RENDER_ATTACHMENT}),h=a.createBuffer({size:192,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),g=(0,N.a1)([0],[GPUShaderStage.VERTEX],["buffer"],[{type:"uniform"}],[[{buffer:h}]],"Camera",a),b=a.createBuffer({size:2*Uint32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),y=(0,N.a1)([0],[GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT],["buffer"],[{type:"uniform"}],[[{buffer:b}]],"General",a),v=a.createBindGroupLayout({label:"NodeUniforms.bindGroupLayout",entries:[{binding:0,buffer:{type:"uniform"},visibility:GPUShaderStage.VERTEX}]}),T=await fetch("../assets/gltf/whale.glb").then(e=>e.arrayBuffer()).then(e=>I(e,a));T.meshes[0].buildRenderPipeline(a,k,k,u,p.format,[g.bindGroupLayout,y.bindGroupLayout,v,C.skinBindGroupLayout]);let G=O(a),w={size:320,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_DST},x=a.createBuffer(w),S=a.createBuffer(w),B=(0,N.a1)([0,1],[GPUShaderStage.VERTEX,GPUShaderStage.VERTEX],["buffer","buffer"],[{type:"read-only-storage"},{type:"read-only-storage"}],[[{buffer:x},{buffer:S}]],"SkinnedGridJointUniforms",a),E=V(a,u,A.Z,A.Z,[g.bindGroupLayout,y.bindGroupLayout,B.bindGroupLayout]),M=n.width/n.height,U=m._E.perspective(2*Math.PI/5,M,.1,100),L=m._E.ortho(-20,20,-10,10,-100,100),P={colorAttachments:[{view:void 0,clearValue:{r:.3,g:.3,b:.3,a:1},loadOp:"clear",storeOp:"store"}],depthStencilAttachment:{view:p.createView(),depthLoadOp:"clear",depthClearValue:1,depthStoreOp:"store"}},j={colorAttachments:[{view:void 0,clearValue:{r:.3,g:.3,b:.3,a:1},loadOp:"clear",storeOp:"store"}]},_=(e,n)=>{let t=m._E.identity();m._E.rotateZ(t,n,e[0]),m._E.translate(e[0],m.R3.create(4,0,0),t),m._E.rotateZ(t,n,e[1]),m._E.translate(e[1],m.R3.create(4,0,0),t),m._E.rotateZ(t,n,e[2])},F=(e=>{let n=[],t=[];for(let r=0;r<5;r++)n.push(m._E.identity()),t.push(m._E.identity());_(t,0);let i=t.map(e=>m._E.inverse(e));return{transforms:n,bindPoses:t,bindPosesInv:i}})(0);for(let D=0;D<F.bindPosesInv.length;D++)a.queue.writeBuffer(S,64*D,F.bindPosesInv[D]);let W=new Map,Y=(e,n)=>{for(let t=0;t<e.joints.length;t++){let r=e.joints[t];W.has(r)||W.set(r,T.nodes[r].source.getMatrix());let i=W.get(r),a=m._E.create();a=1===r||0===r?m._E.rotateY(i,-n):3===r||4===r?m._E.rotateX(i,3===r?n:-n):m._E.rotateZ(i,n),T.nodes[r].source.position=m._E.getTranslation(a),T.nodes[r].source.scale=m._E.getScaling(a),T.nodes[r].source.rotation=q(a)}};requestAnimationFrame(function e(){if(!t.active)return;let n="Skinned Grid"!==c.object?U:L,r=function(){let e=m._E.identity();return"Skinned Grid"===c.object?m._E.translate(e,m.R3.fromValues(c.cameraX*c.objectScale,c.cameraY*c.objectScale,c.cameraZ),e):m._E.translate(e,m.R3.fromValues(c.cameraX,c.cameraY,c.cameraZ),e),e}(),i=function(){let e=m._E.identity(),n=m.R3.fromValues(c.objectScale,c.objectScale,c.objectScale);return m._E.scale(e,n,e),"Whale"===c.object&&m._E.rotateY(e,Date.now()/1e3*.5,e),e}(),o=Date.now()/2e4*c.speed,u=Math.sin(o)*c.angle;_(F.transforms,u),a.queue.writeBuffer(h,0,n.buffer,n.byteOffset,n.byteLength),a.queue.writeBuffer(h,64,r.buffer,r.byteOffset,r.byteLength),a.queue.writeBuffer(h,128,i.buffer,i.byteOffset,i.byteLength);for(let d=0;d<F.transforms.length;d++)a.queue.writeBuffer(x,64*d,F.transforms[d]);for(let f of(P.colorAttachments[0].view=s.getCurrentTexture().createView(),j.colorAttachments[0].view=s.getCurrentTexture().createView(),T.scenes))f.root.updateWorldMatrix(a);Y(T.skins[0],Math.sin(o)*c.angle),T.skins[0].update(a,6,T.nodes);let l=a.createCommandEncoder();if("Whale"===c.object){let p=l.beginRenderPass(P);for(let b of T.scenes)b.root.renderDrawables(p,[g.bindGroups[0],y.bindGroups[0]]);p.end()}else{let v=l.beginRenderPass(j);v.setPipeline(E),v.setBindGroup(0,g.bindGroups[0]),v.setBindGroup(1,y.bindGroups[0]),v.setBindGroup(2,B.bindGroups[0]),v.setVertexBuffer(0,G.positions),v.setVertexBuffer(1,G.joints),v.setVertexBuffer(2,G.weights),v.setIndexBuffer(G.indices,"uint16"),v.drawIndexed(R.length,1),v.end()}a.queue.submit([l.finish()]),requestAnimationFrame(e)})},Y=()=>(0,p.Tl)({name:"Skinned Mesh",description:"A demonstration of basic gltf loading and mesh skinning, ported from https://webgl2fundamentals.org/webgl/lessons/webgl-skinning.html. Mesh data, per vertex attributes, and skin inverseBindMatrices are taken from the json parsed from the binary output of the .glb file. Animations are generated progrmatically, with animated joint matrices updated and passed to shaders per frame via uniform buffers.",init:W,gui:!0,sources:[{name:D.substring(23),contents:"import { makeSample, SampleInit } from '../../components/SampleLayout';\nimport { convertGLBToJSONAndBinary, GLTFSkin } from './glbUtils';\nimport gltfWGSL from './gltf.wgsl';\nimport gridWGSL from './grid.wgsl';\nimport { Mat4, mat4, Quat, vec3 } from 'wgpu-matrix';\nimport { createBindGroupCluster } from '../bitonicSort/utils';\nimport {\n  createSkinnedGridBuffers,\n  createSkinnedGridRenderPipeline,\n} from './gridUtils';\nimport { gridIndices } from './gridData';\n\nconst MAT4X4_BYTES = 64;\n\ninterface BoneObject {\n  transforms: Mat4[];\n  bindPoses: Mat4[];\n  bindPosesInv: Mat4[];\n}\n\nenum RenderMode {\n  NORMAL,\n  JOINTS,\n  WEIGHTS,\n}\n\nenum SkinMode {\n  ON,\n  OFF,\n}\n\n// Copied from toji/gl-matrix\nconst getRotation = (mat: Mat4): Quat => {\n  // Initialize our output quaternion\n  const out = [0, 0, 0, 0];\n  // Extract the scaling factor from the final matrix transformation\n  // to normalize our rotation;\n  const scaling = mat4.getScaling(mat);\n  const is1 = 1 / scaling[0];\n  const is2 = 1 / scaling[1];\n  const is3 = 1 / scaling[2];\n\n  // Scale the matrix elements by the scaling factors\n  const sm11 = mat[0] * is1;\n  const sm12 = mat[1] * is2;\n  const sm13 = mat[2] * is3;\n  const sm21 = mat[4] * is1;\n  const sm22 = mat[5] * is2;\n  const sm23 = mat[6] * is3;\n  const sm31 = mat[8] * is1;\n  const sm32 = mat[9] * is2;\n  const sm33 = mat[10] * is3;\n\n  // The trace of a square matrix is the sum of its diagonal entries\n  // While the matrix trace has many interesting mathematical properties,\n  // the primary purpose of the trace is to assess the characteristics of the rotation.\n  const trace = sm11 + sm22 + sm33;\n  let S = 0;\n\n  // If all matrix elements contribute equally to the rotation.\n  if (trace > 0) {\n    S = Math.sqrt(trace + 1.0) * 2;\n    out[3] = 0.25 * S;\n    out[0] = (sm23 - sm32) / S;\n    out[1] = (sm31 - sm13) / S;\n    out[2] = (sm12 - sm21) / S;\n    // If the rotation is primarily around the x-axis\n  } else if (sm11 > sm22 && sm11 > sm33) {\n    S = Math.sqrt(1.0 + sm11 - sm22 - sm33) * 2;\n    out[3] = (sm23 - sm32) / S;\n    out[0] = 0.25 * S;\n    out[1] = (sm12 + sm21) / S;\n    out[2] = (sm31 + sm13) / S;\n    // If rotation is primarily around the y-axis\n  } else if (sm22 > sm33) {\n    S = Math.sqrt(1.0 + sm22 - sm11 - sm33) * 2;\n    out[3] = (sm31 - sm13) / S;\n    out[0] = (sm12 + sm21) / S;\n    out[1] = 0.25 * S;\n    out[2] = (sm23 + sm32) / S;\n    // If the rotation is primarily around the z-axis\n  } else {\n    S = Math.sqrt(1.0 + sm33 - sm11 - sm22) * 2;\n    out[3] = (sm12 - sm21) / S;\n    out[0] = (sm31 + sm13) / S;\n    out[1] = (sm23 + sm32) / S;\n    out[2] = 0.25 * S;\n  }\n\n  return out;\n};\n\nconst init: SampleInit = async ({ canvas, pageState, gui }) => {\n  //Normal setup\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  if (!pageState.active) return;\n  const context = canvas.getContext('webgpu') as GPUCanvasContext;\n\n  const devicePixelRatio = window.devicePixelRatio || 1;\n  canvas.width = canvas.clientWidth * devicePixelRatio;\n  canvas.height = canvas.clientHeight * devicePixelRatio;\n  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n\n  context.configure({\n    device,\n    format: presentationFormat,\n    alphaMode: 'premultiplied',\n  });\n\n  const settings = {\n    cameraX: 0,\n    cameraY: -5.1,\n    cameraZ: -14.6,\n    objectScale: 1,\n    angle: 0.2,\n    speed: 50,\n    object: 'Whale',\n    renderMode: 'NORMAL',\n    skinMode: 'ON',\n  };\n\n  // Determine whether we want to render our whale or our skinned grid\n  gui.add(settings, 'object', ['Whale', 'Skinned Grid']).onChange(() => {\n    if (settings.object === 'Skinned Grid') {\n      settings.cameraX = -10;\n      settings.cameraY = 0;\n      settings.objectScale = 1.27;\n    } else {\n      if (settings.skinMode === 'OFF') {\n        settings.cameraX = 0;\n        settings.cameraY = 0;\n        settings.cameraZ = -11;\n      } else {\n        settings.cameraX = 0;\n        settings.cameraY = -5.1;\n        settings.cameraZ = -14.6;\n      }\n    }\n  });\n\n  // Output the mesh normals, its joints, or the weights that influence the movement of the joints\n  gui\n    .add(settings, 'renderMode', ['NORMAL', 'JOINTS', 'WEIGHTS'])\n    .onChange(() => {\n      device.queue.writeBuffer(\n        generalUniformsBuffer,\n        0,\n        new Uint32Array([RenderMode[settings.renderMode]])\n      );\n    });\n  // Determine whether the mesh is static or whether skinning is activated\n  gui.add(settings, 'skinMode', ['ON', 'OFF']).onChange(() => {\n    if (settings.object === 'Whale') {\n      if (settings.skinMode === 'OFF') {\n        settings.cameraX = 0;\n        settings.cameraY = 0;\n        settings.cameraZ = -11;\n      } else {\n        settings.cameraX = 0;\n        settings.cameraY = -5.1;\n        settings.cameraZ = -14.6;\n      }\n    }\n    device.queue.writeBuffer(\n      generalUniformsBuffer,\n      4,\n      new Uint32Array([SkinMode[settings.skinMode]])\n    );\n  });\n  const animFolder = gui.addFolder('Animation Settings');\n  animFolder.add(settings, 'angle', 0.05, 0.5).step(0.05);\n  animFolder.add(settings, 'speed', 10, 100).step(10);\n\n  const depthTexture = device.createTexture({\n    size: [canvas.width, canvas.height],\n    format: 'depth24plus',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const cameraBuffer = device.createBuffer({\n    size: MAT4X4_BYTES * 3,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const cameraBGCluster = createBindGroupCluster(\n    [0],\n    [GPUShaderStage.VERTEX],\n    ['buffer'],\n    [{ type: 'uniform' }],\n    [[{ buffer: cameraBuffer }]],\n    'Camera',\n    device\n  );\n\n  const generalUniformsBuffer = device.createBuffer({\n    size: Uint32Array.BYTES_PER_ELEMENT * 2,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const generalUniformsBGCLuster = createBindGroupCluster(\n    [0],\n    [GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT],\n    ['buffer'],\n    [{ type: 'uniform' }],\n    [[{ buffer: generalUniformsBuffer }]],\n    'General',\n    device\n  );\n\n  // Same bindGroupLayout as in main file.\n  const nodeUniformsBindGroupLayout = device.createBindGroupLayout({\n    label: 'NodeUniforms.bindGroupLayout',\n    entries: [\n      {\n        binding: 0,\n        buffer: {\n          type: 'uniform',\n        },\n        visibility: GPUShaderStage.VERTEX,\n      },\n    ],\n  });\n\n  // Fetch whale resources from the glb file\n  const whaleScene = await fetch('../assets/gltf/whale.glb')\n    .then((res) => res.arrayBuffer())\n    .then((buffer) => convertGLBToJSONAndBinary(buffer, device));\n\n  // Builds a render pipeline for our whale mesh\n  // Since we are building a lightweight gltf parser around a gltf scene with a known\n  // quantity of meshes, we only build a renderPipeline for the singular mesh present\n  // within our scene. A more robust gltf parser would loop through all the meshes,\n  // cache replicated pipelines, and perform other optimizations.\n  whaleScene.meshes[0].buildRenderPipeline(\n    device,\n    gltfWGSL,\n    gltfWGSL,\n    presentationFormat,\n    depthTexture.format,\n    [\n      cameraBGCluster.bindGroupLayout,\n      generalUniformsBGCLuster.bindGroupLayout,\n      nodeUniformsBindGroupLayout,\n      GLTFSkin.skinBindGroupLayout,\n    ]\n  );\n\n  // Create skinned grid resources\n  const skinnedGridVertexBuffers = createSkinnedGridBuffers(device);\n  // Buffer for our uniforms, joints, and inverse bind matrices\n  const skinnedGridUniformBufferUsage: GPUBufferDescriptor = {\n    // 5 4x4 matrices, one for each bone\n    size: MAT4X4_BYTES * 5,\n    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n  };\n  const skinnedGridJointUniformBuffer = device.createBuffer(\n    skinnedGridUniformBufferUsage\n  );\n  const skinnedGridInverseBindUniformBuffer = device.createBuffer(\n    skinnedGridUniformBufferUsage\n  );\n  const skinnedGridBoneBGCluster = createBindGroupCluster(\n    [0, 1],\n    [GPUShaderStage.VERTEX, GPUShaderStage.VERTEX],\n    ['buffer', 'buffer'],\n    [{ type: 'read-only-storage' }, { type: 'read-only-storage' }],\n    [\n      [\n        { buffer: skinnedGridJointUniformBuffer },\n        { buffer: skinnedGridInverseBindUniformBuffer },\n      ],\n    ],\n    'SkinnedGridJointUniforms',\n    device\n  );\n  const skinnedGridPipeline = createSkinnedGridRenderPipeline(\n    device,\n    presentationFormat,\n    gridWGSL,\n    gridWGSL,\n    [\n      cameraBGCluster.bindGroupLayout,\n      generalUniformsBGCLuster.bindGroupLayout,\n      skinnedGridBoneBGCluster.bindGroupLayout,\n    ]\n  );\n\n  // Global Calc\n  const aspect = canvas.width / canvas.height;\n  const perspectiveProjection = mat4.perspective(\n    (2 * Math.PI) / 5,\n    aspect,\n    0.1,\n    100.0\n  );\n\n  const orthographicProjection = mat4.ortho(-20, 20, -10, 10, -100, 100);\n\n  function getProjectionMatrix() {\n    if (settings.object !== 'Skinned Grid') {\n      return perspectiveProjection as Float32Array;\n    }\n    return orthographicProjection as Float32Array;\n  }\n\n  function getViewMatrix() {\n    const viewMatrix = mat4.identity();\n    if (settings.object === 'Skinned Grid') {\n      mat4.translate(\n        viewMatrix,\n        vec3.fromValues(\n          settings.cameraX * settings.objectScale,\n          settings.cameraY * settings.objectScale,\n          settings.cameraZ\n        ),\n        viewMatrix\n      );\n    } else {\n      mat4.translate(\n        viewMatrix,\n        vec3.fromValues(settings.cameraX, settings.cameraY, settings.cameraZ),\n        viewMatrix\n      );\n    }\n    return viewMatrix as Float32Array;\n  }\n\n  function getModelMatrix() {\n    const modelMatrix = mat4.identity();\n    const scaleVector = vec3.fromValues(\n      settings.objectScale,\n      settings.objectScale,\n      settings.objectScale\n    );\n    mat4.scale(modelMatrix, scaleVector, modelMatrix);\n    if (settings.object === 'Whale') {\n      mat4.rotateY(modelMatrix, (Date.now() / 1000) * 0.5, modelMatrix);\n    }\n    return modelMatrix as Float32Array;\n  }\n\n  // Pass Descriptor for GLTFs\n  const gltfRenderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        view: undefined, // Assigned later\n\n        clearValue: { r: 0.3, g: 0.3, b: 0.3, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n      depthLoadOp: 'clear',\n      depthClearValue: 1.0,\n      depthStoreOp: 'store',\n    },\n  };\n\n  // Pass descriptor for grid with no depth testing\n  const skinnedGridRenderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        view: undefined, // Assigned later\n\n        clearValue: { r: 0.3, g: 0.3, b: 0.3, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n  };\n\n  const animSkinnedGrid = (boneTransforms: Mat4[], angle: number) => {\n    const m = mat4.identity();\n    mat4.rotateZ(m, angle, boneTransforms[0]);\n    mat4.translate(boneTransforms[0], vec3.create(4, 0, 0), m);\n    mat4.rotateZ(m, angle, boneTransforms[1]);\n    mat4.translate(boneTransforms[1], vec3.create(4, 0, 0), m);\n    mat4.rotateZ(m, angle, boneTransforms[2]);\n  };\n\n  // Create a group of bones\n  // Each index associates an actual bone to its transforms, bindPoses, uniforms, etc\n  const createBoneCollection = (numBones: number): BoneObject => {\n    // Initial bone transformation\n    const transforms: Mat4[] = [];\n    // Bone bind poses, an extra matrix per joint/bone that represents the starting point\n    // of the bone before any transformations are applied\n    const bindPoses: Mat4[] = [];\n    // Create a transform, bind pose, and inverse bind pose for each bone\n    for (let i = 0; i < numBones; i++) {\n      transforms.push(mat4.identity());\n      bindPoses.push(mat4.identity());\n    }\n\n    // Get initial bind pose positions\n    animSkinnedGrid(bindPoses, 0);\n    const bindPosesInv = bindPoses.map((bindPose) => {\n      return mat4.inverse(bindPose);\n    });\n\n    return {\n      transforms,\n      bindPoses,\n      bindPosesInv,\n    };\n  };\n\n  // Create bones of the skinned grid and write the inverse bind positions to\n  // the skinned grid's inverse bind matrix array\n  const gridBoneCollection = createBoneCollection(5);\n  for (let i = 0; i < gridBoneCollection.bindPosesInv.length; i++) {\n    device.queue.writeBuffer(\n      skinnedGridInverseBindUniformBuffer,\n      i * 64,\n      gridBoneCollection.bindPosesInv[i] as Float32Array\n    );\n  }\n\n  // A map that maps a joint index to the original matrix transformation of a bone\n  const origMatrices = new Map<number, Mat4>();\n  const animWhaleSkin = (skin: GLTFSkin, angle: number) => {\n    for (let i = 0; i < skin.joints.length; i++) {\n      // Index into the current joint\n      const joint = skin.joints[i];\n      // If our map does\n      if (!origMatrices.has(joint)) {\n        origMatrices.set(joint, whaleScene.nodes[joint].source.getMatrix());\n      }\n      // Get the original position, rotation, and scale of the current joint\n      const origMatrix = origMatrices.get(joint);\n      let m = mat4.create();\n      // Depending on which bone we are accessing, apply a specific rotation to the bone's original\n      // transformation to animate it\n      if (joint === 1 || joint === 0) {\n        m = mat4.rotateY(origMatrix, -angle);\n      } else if (joint === 3 || joint === 4) {\n        m = mat4.rotateX(origMatrix, joint === 3 ? angle : -angle);\n      } else {\n        m = mat4.rotateZ(origMatrix, angle);\n      }\n      // Apply the current transformation to the transform values within the relevant nodes\n      // (these nodes, of course, each being nodes that represent joints/bones)\n      whaleScene.nodes[joint].source.position = mat4.getTranslation(m);\n      whaleScene.nodes[joint].source.scale = mat4.getScaling(m);\n      whaleScene.nodes[joint].source.rotation = getRotation(m);\n    }\n  };\n\n  function frame() {\n    // Sample is no longer the active page.\n    if (!pageState.active) return;\n\n    // Calculate camera matrices\n    const projectionMatrix = getProjectionMatrix();\n    const viewMatrix = getViewMatrix();\n    const modelMatrix = getModelMatrix();\n\n    // Calculate bone transformation\n    const t = (Date.now() / 20000) * settings.speed;\n    const angle = Math.sin(t) * settings.angle;\n    // Compute Transforms when angle is applied\n    animSkinnedGrid(gridBoneCollection.transforms, angle);\n\n    // Write to mvp to camera buffer\n    device.queue.writeBuffer(\n      cameraBuffer,\n      0,\n      projectionMatrix.buffer,\n      projectionMatrix.byteOffset,\n      projectionMatrix.byteLength\n    );\n\n    device.queue.writeBuffer(\n      cameraBuffer,\n      64,\n      viewMatrix.buffer,\n      viewMatrix.byteOffset,\n      viewMatrix.byteLength\n    );\n\n    device.queue.writeBuffer(\n      cameraBuffer,\n      128,\n      modelMatrix.buffer,\n      modelMatrix.byteOffset,\n      modelMatrix.byteLength\n    );\n\n    // Write to skinned grid bone uniform buffer\n    for (let i = 0; i < gridBoneCollection.transforms.length; i++) {\n      device.queue.writeBuffer(\n        skinnedGridJointUniformBuffer,\n        i * 64,\n        gridBoneCollection.transforms[i] as Float32Array\n      );\n    }\n\n    // Difference between these two render passes is just the presence of depthTexture\n    gltfRenderPassDescriptor.colorAttachments[0].view = context\n      .getCurrentTexture()\n      .createView();\n\n    skinnedGridRenderPassDescriptor.colorAttachments[0].view = context\n      .getCurrentTexture()\n      .createView();\n\n    // Update node matrixes\n    for (const scene of whaleScene.scenes) {\n      scene.root.updateWorldMatrix(device);\n    }\n\n    // Updates skins (we index into skins in the renderer, which is not the best approach but hey)\n    animWhaleSkin(whaleScene.skins[0], Math.sin(t) * settings.angle);\n    // Node 6 should be the only node with a drawable mesh so hopefully this works fine\n    whaleScene.skins[0].update(device, 6, whaleScene.nodes);\n\n    const commandEncoder = device.createCommandEncoder();\n    if (settings.object === 'Whale') {\n      const passEncoder = commandEncoder.beginRenderPass(\n        gltfRenderPassDescriptor\n      );\n      for (const scene of whaleScene.scenes) {\n        scene.root.renderDrawables(passEncoder, [\n          cameraBGCluster.bindGroups[0],\n          generalUniformsBGCLuster.bindGroups[0],\n        ]);\n      }\n      passEncoder.end();\n    } else {\n      // Our skinned grid isn't checking for depth, so we pass it\n      // a separate render descriptor that does not take in a depth texture\n      const passEncoder = commandEncoder.beginRenderPass(\n        skinnedGridRenderPassDescriptor\n      );\n      passEncoder.setPipeline(skinnedGridPipeline);\n      passEncoder.setBindGroup(0, cameraBGCluster.bindGroups[0]);\n      passEncoder.setBindGroup(1, generalUniformsBGCLuster.bindGroups[0]);\n      passEncoder.setBindGroup(2, skinnedGridBoneBGCluster.bindGroups[0]);\n      // Pass in vertex and index buffers generated from our static skinned grid\n      // data at ./gridData.ts\n      passEncoder.setVertexBuffer(0, skinnedGridVertexBuffers.positions);\n      passEncoder.setVertexBuffer(1, skinnedGridVertexBuffers.joints);\n      passEncoder.setVertexBuffer(2, skinnedGridVertexBuffers.weights);\n      passEncoder.setIndexBuffer(skinnedGridVertexBuffers.indices, 'uint16');\n      passEncoder.drawIndexed(gridIndices.length, 1);\n      passEncoder.end();\n    }\n\n    device.queue.submit([commandEncoder.finish()]);\n\n    requestAnimationFrame(frame);\n  }\n  requestAnimationFrame(frame);\n};\n\nconst skinnedMesh: () => JSX.Element = () =>\n  makeSample({\n    name: 'Skinned Mesh',\n    description:\n      'A demonstration of basic gltf loading and mesh skinning, ported from https://webgl2fundamentals.org/webgl/lessons/webgl-skinning.html. Mesh data, per vertex attributes, and skin inverseBindMatrices are taken from the json parsed from the binary output of the .glb file. Animations are generated progrmatically, with animated joint matrices updated and passed to shaders per frame via uniform buffers.',\n    init,\n    gui: true,\n    sources: [\n      {\n        name: __filename.substring(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: './gridData.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!./gridData.ts').default,\n      },\n      {\n        name: './gridUtils.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!./gridUtils.ts').default,\n      },\n      {\n        name: './grid.wgsl',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!./grid.wgsl').default,\n      },\n      {\n        name: './gltf.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!./gltf.ts').default,\n      },\n      {\n        name: './glbUtils.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!./glbUtils.ts').default,\n      },\n      {\n        name: './gltf.wgsl',\n        contents: gltfWGSL,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default skinnedMesh;\n"},{name:"./gridData.ts",contents:t(6270).Z},{name:"./gridUtils.ts",contents:t(9483).Z},{name:"./grid.wgsl",contents:t(2624).Z},{name:"./gltf.ts",contents:t(6370).Z},{name:"./glbUtils.ts",contents:t(7674).Z},{name:"./gltf.wgsl",contents:k}],filename:D});var z=Y},9147:function(e){e.exports={canvasContainer:"SampleLayout_canvasContainer__zRR_l",sourceFileNav:"SampleLayout_sourceFileNav__ml48P",sourceFileScrollContainer:"SampleLayout_sourceFileScrollContainer__LsNEm",sourceFileContainer:"SampleLayout_sourceFileContainer__3s84x"}},7674:function(e,n){"use strict";n.Z="import { Quat } from 'wgpu-matrix/dist/2.x/quat';\nimport { Accessor, BufferView, GlTf, Scene } from './gltf';\nimport { Mat4, Vec3, mat4 } from 'wgpu-matrix';\n\n//NOTE: GLTF code is not generally extensible to all gltf models\n// Modified from Will Usher code found at this link https://www.willusher.io/graphics/2023/05/16/0-to-gltf-first-mesh\n\n// Associates the mode paramete of a gltf primitive object with the primitive's intended render mode\nenum GLTFRenderMode {\n  POINTS = 0,\n  LINE = 1,\n  LINE_LOOP = 2,\n  LINE_STRIP = 3,\n  TRIANGLES = 4,\n  TRIANGLE_STRIP = 5,\n  TRIANGLE_FAN = 6,\n}\n\n// Determines how to interpret each element of the structure that is accessed from our accessor\nenum GLTFDataComponentType {\n  BYTE = 5120,\n  UNSIGNED_BYTE = 5121,\n  SHORT = 5122,\n  UNSIGNED_SHORT = 5123,\n  INT = 5124,\n  UNSIGNED_INT = 5125,\n  FLOAT = 5126,\n  DOUBLE = 5130,\n}\n\n// Determines how to interpret the structure of the values accessed by an accessor\nenum GLTFDataStructureType {\n  SCALAR = 0,\n  VEC2 = 1,\n  VEC3 = 2,\n  VEC4 = 3,\n  MAT2 = 4,\n  MAT3 = 5,\n  MAT4 = 6,\n}\n\nexport const alignTo = (val: number, align: number): number => {\n  return Math.floor((val + align - 1) / align) * align;\n};\n\nconst parseGltfDataStructureType = (type: string) => {\n  switch (type) {\n    case 'SCALAR':\n      return GLTFDataStructureType.SCALAR;\n    case 'VEC2':\n      return GLTFDataStructureType.VEC2;\n    case 'VEC3':\n      return GLTFDataStructureType.VEC3;\n    case 'VEC4':\n      return GLTFDataStructureType.VEC4;\n    case 'MAT2':\n      return GLTFDataStructureType.MAT2;\n    case 'MAT3':\n      return GLTFDataStructureType.MAT3;\n    case 'MAT4':\n      return GLTFDataStructureType.MAT4;\n    default:\n      throw Error(`Unhandled glTF Type ${type}`);\n  }\n};\n\nconst gltfDataStructureTypeNumComponents = (type: GLTFDataStructureType) => {\n  switch (type) {\n    case GLTFDataStructureType.SCALAR:\n      return 1;\n    case GLTFDataStructureType.VEC2:\n      return 2;\n    case GLTFDataStructureType.VEC3:\n      return 3;\n    case GLTFDataStructureType.VEC4:\n    case GLTFDataStructureType.MAT2:\n      return 4;\n    case GLTFDataStructureType.MAT3:\n      return 9;\n    case GLTFDataStructureType.MAT4:\n      return 16;\n    default:\n      throw Error(`Invalid glTF Type ${type}`);\n  }\n};\n\n// Note: only returns non-normalized type names,\n// so byte/ubyte = sint8/uint8, not snorm8/unorm8, same for ushort\nconst gltfVertexType = (\n  componentType: GLTFDataComponentType,\n  type: GLTFDataStructureType\n) => {\n  let typeStr = null;\n  switch (componentType) {\n    case GLTFDataComponentType.BYTE:\n      typeStr = 'sint8';\n      break;\n    case GLTFDataComponentType.UNSIGNED_BYTE:\n      typeStr = 'uint8';\n      break;\n    case GLTFDataComponentType.SHORT:\n      typeStr = 'sint16';\n      break;\n    case GLTFDataComponentType.UNSIGNED_SHORT:\n      typeStr = 'uint16';\n      break;\n    case GLTFDataComponentType.INT:\n      typeStr = 'int32';\n      break;\n    case GLTFDataComponentType.UNSIGNED_INT:\n      typeStr = 'uint32';\n      break;\n    case GLTFDataComponentType.FLOAT:\n      typeStr = 'float32';\n      break;\n    default:\n      throw Error(`Unrecognized or unsupported glTF type ${componentType}`);\n  }\n\n  switch (gltfDataStructureTypeNumComponents(type)) {\n    case 1:\n      return typeStr;\n    case 2:\n      return typeStr + 'x2';\n    case 3:\n      return typeStr + 'x3';\n    case 4:\n      return typeStr + 'x4';\n    // Vertex attributes should never be a matrix type, so we should not hit this\n    // unless we're passed an improperly created gltf file\n    default:\n      throw Error(`Invalid number of components for gltfType: ${type}`);\n  }\n};\n\nconst gltfElementSize = (\n  componentType: GLTFDataComponentType,\n  type: GLTFDataStructureType\n) => {\n  let componentSize = 0;\n  switch (componentType) {\n    case GLTFDataComponentType.BYTE:\n      componentSize = 1;\n      break;\n    case GLTFDataComponentType.UNSIGNED_BYTE:\n      componentSize = 1;\n      break;\n    case GLTFDataComponentType.SHORT:\n      componentSize = 2;\n      break;\n    case GLTFDataComponentType.UNSIGNED_SHORT:\n      componentSize = 2;\n      break;\n    case GLTFDataComponentType.INT:\n      componentSize = 4;\n      break;\n    case GLTFDataComponentType.UNSIGNED_INT:\n      componentSize = 4;\n      break;\n    case GLTFDataComponentType.FLOAT:\n      componentSize = 4;\n      break;\n    case GLTFDataComponentType.DOUBLE:\n      componentSize = 8;\n      break;\n    default:\n      throw Error('Unrecognized GLTF Component Type?');\n  }\n  return gltfDataStructureTypeNumComponents(type) * componentSize;\n};\n\n// Convert differently depending on if the shader is a vertex or compute shader\nconst convertGPUVertexFormatToWGSLFormat = (vertexFormat: GPUVertexFormat) => {\n  switch (vertexFormat) {\n    case 'float32': {\n      return 'f32';\n    }\n    case 'float32x2': {\n      return 'vec2<f32>';\n    }\n    case 'float32x3': {\n      return 'vec3<f32>';\n    }\n    case 'float32x4': {\n      return 'vec4<f32>';\n    }\n    case 'uint32': {\n      return 'u32';\n    }\n    case 'uint32x2': {\n      return 'vec2<u32>';\n    }\n    case 'uint32x3': {\n      return 'vec3<u32>';\n    }\n    case 'uint32x4': {\n      return 'vec4<u32>';\n    }\n    case 'uint8x2': {\n      return 'vec2<u32>';\n    }\n    case 'uint8x4': {\n      return 'vec4<u32>';\n    }\n    case 'uint16x4': {\n      return 'vec4<u32>';\n    }\n    case 'uint16x2': {\n      return 'vec2<u32>';\n    }\n    default: {\n      return 'f32';\n    }\n  }\n};\n\nexport class GLTFBuffer {\n  buffer: Uint8Array;\n  constructor(buffer: ArrayBuffer, offset: number, size: number) {\n    this.buffer = new Uint8Array(buffer, offset, size);\n  }\n}\n\nexport class GLTFBufferView {\n  byteLength: number;\n  byteStride: number;\n  view: Uint8Array;\n  needsUpload: boolean;\n  gpuBuffer: GPUBuffer;\n  usage: number;\n  constructor(buffer: GLTFBuffer, view: BufferView) {\n    this.byteLength = view['byteLength'];\n    this.byteStride = 0;\n    if (view['byteStride'] !== undefined) {\n      this.byteStride = view['byteStride'];\n    }\n    // Create the buffer view. Note that subarray creates a new typed\n    // view over the same array buffer, we do not make a copy here.\n    let viewOffset = 0;\n    if (view['byteOffset'] !== undefined) {\n      viewOffset = view['byteOffset'];\n    }\n    // NOTE: This creates a uint8array view into the buffer!\n    // When we call .buffer on this view, it will give us back the original array buffer\n    // Accordingly, when converting our buffer from a uint8array to a float32array representation\n    // we need to apply the byte offset of our view when creating our buffer\n    // ie new Float32Array(this.view.buffer, this.view.byteOffset, this.view.byteLength)\n    this.view = buffer.buffer.subarray(\n      viewOffset,\n      viewOffset + this.byteLength\n    );\n\n    this.needsUpload = false;\n    this.gpuBuffer = null;\n    this.usage = 0;\n  }\n\n  addUsage(usage: number) {\n    this.usage = this.usage | usage;\n  }\n\n  upload(device: GPUDevice) {\n    // Note: must align to 4 byte size when mapped at creation is true\n    const buf: GPUBuffer = device.createBuffer({\n      size: alignTo(this.view.byteLength, 4),\n      usage: this.usage,\n      mappedAtCreation: true,\n    });\n    new Uint8Array(buf.getMappedRange()).set(this.view);\n    buf.unmap();\n    this.gpuBuffer = buf;\n    this.needsUpload = false;\n  }\n}\n\nexport class GLTFAccessor {\n  count: number;\n  componentType: GLTFDataComponentType;\n  structureType: GLTFDataStructureType;\n  view: GLTFBufferView;\n  byteOffset: number;\n  constructor(view: GLTFBufferView, accessor: Accessor) {\n    this.count = accessor['count'];\n    this.componentType = accessor['componentType'];\n    this.structureType = parseGltfDataStructureType(accessor['type']);\n    this.view = view;\n    this.byteOffset = 0;\n    if (accessor['byteOffset'] !== undefined) {\n      this.byteOffset = accessor['byteOffset'];\n    }\n  }\n\n  get byteStride() {\n    const elementSize = gltfElementSize(this.componentType, this.structureType);\n    return Math.max(elementSize, this.view.byteStride);\n  }\n\n  get byteLength() {\n    return this.count * this.byteStride;\n  }\n\n  // Get the vertex attribute type for accessors that are used as vertex attributes\n  get vertexType() {\n    return gltfVertexType(this.componentType, this.structureType);\n  }\n}\n\ninterface AttributeMapInterface {\n  [key: string]: GLTFAccessor;\n}\n\nexport class GLTFPrimitive {\n  topology: GLTFRenderMode;\n  renderPipeline: GPURenderPipeline;\n  private attributeMap: AttributeMapInterface;\n  private attributes: string[] = [];\n  constructor(\n    topology: GLTFRenderMode,\n    attributeMap: AttributeMapInterface,\n    attributes: string[]\n  ) {\n    this.topology = topology;\n    this.renderPipeline = null;\n    // Maps attribute names to accessors\n    this.attributeMap = attributeMap;\n    this.attributes = attributes;\n\n    for (const key in this.attributeMap) {\n      this.attributeMap[key].view.needsUpload = true;\n      if (key === 'INDICES') {\n        this.attributeMap['INDICES'].view.addUsage(GPUBufferUsage.INDEX);\n        continue;\n      }\n      this.attributeMap[key].view.addUsage(GPUBufferUsage.VERTEX);\n    }\n  }\n\n  buildRenderPipeline(\n    device: GPUDevice,\n    vertexShader: string,\n    fragmentShader: string,\n    colorFormat: GPUTextureFormat,\n    depthFormat: GPUTextureFormat,\n    bgLayouts: GPUBindGroupLayout[],\n    label: string\n  ) {\n    // For now, just check if the attributeMap contains a given attribute using map.has(), and add it if it does\n    // POSITION, NORMAL, TEXCOORD_0, JOINTS_0, WEIGHTS_0 for order\n    // Vertex attribute state and shader stage\n    let VertexInputShaderString = `struct VertexInput {\\n`;\n    const vertexBuffers: GPUVertexBufferLayout[] = this.attributes.map(\n      (attr, idx) => {\n        const vertexFormat: GPUVertexFormat =\n          this.attributeMap[attr].vertexType;\n        const attrString = attr.toLowerCase().replace(/_0$/, '');\n        VertexInputShaderString += `\\t@location(${idx}) ${attrString}: ${convertGPUVertexFormatToWGSLFormat(\n          vertexFormat\n        )},\\n`;\n        return {\n          arrayStride: this.attributeMap[attr].byteStride,\n          attributes: [\n            {\n              format: this.attributeMap[attr].vertexType,\n              offset: this.attributeMap[attr].byteOffset,\n              shaderLocation: idx,\n            },\n          ],\n        } as GPUVertexBufferLayout;\n      }\n    );\n    VertexInputShaderString += '}';\n\n    const vertexState: GPUVertexState = {\n      // Shader stage info\n      module: device.createShaderModule({\n        code: VertexInputShaderString + vertexShader,\n      }),\n      entryPoint: 'vertexMain',\n      buffers: vertexBuffers,\n    };\n\n    const fragmentState: GPUFragmentState = {\n      // Shader info\n      module: device.createShaderModule({\n        code: VertexInputShaderString + fragmentShader,\n      }),\n      entryPoint: 'fragmentMain',\n      // Output render target info\n      targets: [{ format: colorFormat }],\n    };\n\n    // Our loader only supports triangle lists and strips, so by default we set\n    // the primitive topology to triangle list, and check if it's instead a triangle strip\n    const primitive: GPUPrimitiveState = { topology: 'triangle-list' };\n    if (this.topology == GLTFRenderMode.TRIANGLE_STRIP) {\n      primitive.topology = 'triangle-strip';\n      primitive.stripIndexFormat = this.attributeMap['INDICES'].vertexType;\n    }\n\n    const layout: GPUPipelineLayout = device.createPipelineLayout({\n      bindGroupLayouts: bgLayouts,\n      label: `${label}.pipelineLayout`,\n    });\n\n    const rpDescript: GPURenderPipelineDescriptor = {\n      layout: layout,\n      label: `${label}.pipeline`,\n      vertex: vertexState,\n      fragment: fragmentState,\n      primitive: primitive,\n      depthStencil: {\n        format: depthFormat,\n        depthWriteEnabled: true,\n        depthCompare: 'less',\n      },\n    };\n\n    this.renderPipeline = device.createRenderPipeline(rpDescript);\n  }\n\n  render(renderPassEncoder: GPURenderPassEncoder, bindGroups: GPUBindGroup[]) {\n    renderPassEncoder.setPipeline(this.renderPipeline);\n    bindGroups.forEach((bg, idx) => {\n      renderPassEncoder.setBindGroup(idx, bg);\n    });\n\n    //if skin do something with bone bind group\n    this.attributes.map((attr, idx) => {\n      renderPassEncoder.setVertexBuffer(\n        idx,\n        this.attributeMap[attr].view.gpuBuffer,\n        this.attributeMap[attr].byteOffset,\n        this.attributeMap[attr].byteLength\n      );\n    });\n\n    if (this.attributeMap['INDICES']) {\n      renderPassEncoder.setIndexBuffer(\n        this.attributeMap['INDICES'].view.gpuBuffer,\n        this.attributeMap['INDICES'].vertexType,\n        this.attributeMap['INDICES'].byteOffset,\n        this.attributeMap['INDICES'].byteLength\n      );\n      renderPassEncoder.drawIndexed(this.attributeMap['INDICES'].count);\n    } else {\n      renderPassEncoder.draw(this.attributeMap['POSITION'].count);\n    }\n  }\n}\n\nexport class GLTFMesh {\n  name: string;\n  primitives: GLTFPrimitive[];\n  constructor(name: string, primitives: GLTFPrimitive[]) {\n    this.name = name;\n    this.primitives = primitives;\n  }\n\n  buildRenderPipeline(\n    device: GPUDevice,\n    vertexShader: string,\n    fragmentShader: string,\n    colorFormat: GPUTextureFormat,\n    depthFormat: GPUTextureFormat,\n    bgLayouts: GPUBindGroupLayout[]\n  ) {\n    // We take a pretty simple approach to start. Just loop through all the primitives and\n    // build their respective render pipelines\n    for (let i = 0; i < this.primitives.length; ++i) {\n      this.primitives[i].buildRenderPipeline(\n        device,\n        vertexShader,\n        fragmentShader,\n        colorFormat,\n        depthFormat,\n        bgLayouts,\n        `PrimitivePipeline${i}`\n      );\n    }\n  }\n\n  render(renderPassEncoder: GPURenderPassEncoder, bindGroups: GPUBindGroup[]) {\n    // We take a pretty simple approach to start. Just loop through all the primitives and\n    // call their individual draw methods\n    for (let i = 0; i < this.primitives.length; ++i) {\n      this.primitives[i].render(renderPassEncoder, bindGroups);\n    }\n  }\n}\n\nexport const validateGLBHeader = (header: DataView) => {\n  if (header.getUint32(0, true) != 0x46546c67) {\n    throw Error('Provided file is not a glB file');\n  }\n  if (header.getUint32(4, true) != 2) {\n    throw Error('Provided file is glTF 2.0 file');\n  }\n};\n\nexport const validateBinaryHeader = (header: Uint32Array) => {\n  if (header[1] != 0x004e4942) {\n    throw Error(\n      'Invalid glB: The second chunk of the glB file is not a binary chunk!'\n    );\n  }\n};\n\ntype TempReturn = {\n  meshes: GLTFMesh[];\n  nodes: GLTFNode[];\n  scenes: GLTFScene[];\n  skins: GLTFSkin[];\n};\n\nexport class BaseTransformation {\n  position: Vec3;\n  rotation: Quat;\n  scale: Vec3;\n  constructor(\n    // Identity translation vec3\n    position = [0, 0, 0],\n    // Identity quaternion\n    rotation = [0, 0, 0, 1],\n    // Identity scale vec3\n    scale = [1, 1, 1]\n  ) {\n    this.position = position;\n    this.rotation = rotation;\n    this.scale = scale;\n  }\n  getMatrix(): Mat4 {\n    // Analagous to let transformationMatrix: mat4x4f = translation * rotation * scale;\n    const dst = mat4.identity();\n    // Scale the transformation Matrix\n    mat4.scale(dst, this.scale, dst);\n    // Calculate the rotationMatrix from the quaternion\n    const rotationMatrix = mat4.fromQuat(this.rotation);\n    // Apply the rotation Matrix to the scaleMatrix (rotMat * scaleMat)\n    mat4.multiply(rotationMatrix, dst, dst);\n    // Translate the transformationMatrix\n    mat4.translate(dst, this.position, dst);\n    return dst;\n  }\n}\n\nexport class GLTFNode {\n  name: string;\n  source: BaseTransformation;\n  parent: GLTFNode | null;\n  children: GLTFNode[];\n  // Transforms all node's children in the node's local space, with node itself acting as the origin\n  localMatrix: Mat4;\n  worldMatrix: Mat4;\n  // List of Meshes associated with this node\n  drawables: GLTFMesh[];\n  test = 0;\n  skin?: GLTFSkin;\n  private nodeTransformGPUBuffer: GPUBuffer;\n  private nodeTransformBindGroup: GPUBindGroup;\n\n  constructor(\n    device: GPUDevice,\n    bgLayout: GPUBindGroupLayout,\n    source: BaseTransformation,\n    name?: string,\n    skin?: GLTFSkin\n  ) {\n    this.name = name\n      ? name\n      : `node_${source.position} ${source.rotation} ${source.scale}`;\n    this.source = source;\n    this.parent = null;\n    this.children = [];\n    this.localMatrix = mat4.identity();\n    this.worldMatrix = mat4.identity();\n    this.drawables = [];\n    this.nodeTransformGPUBuffer = device.createBuffer({\n      size: Float32Array.BYTES_PER_ELEMENT * 16,\n      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n    });\n    this.nodeTransformBindGroup = device.createBindGroup({\n      layout: bgLayout,\n      entries: [\n        {\n          binding: 0,\n          resource: {\n            buffer: this.nodeTransformGPUBuffer,\n          },\n        },\n      ],\n    });\n    this.skin = skin;\n  }\n\n  setParent(parent: GLTFNode) {\n    if (this.parent) {\n      this.parent.removeChild(this);\n      this.parent = null;\n    }\n    parent.addChild(this);\n    this.parent = parent;\n  }\n\n  updateWorldMatrix(device: GPUDevice, parentWorldMatrix?: Mat4) {\n    // Get local transform of this particular node, and if the node has a parent,\n    // multiply it against the parent's transform matrix to get transformMatrix relative to world.\n    this.localMatrix = this.source.getMatrix();\n    if (parentWorldMatrix) {\n      mat4.multiply(parentWorldMatrix, this.localMatrix, this.worldMatrix);\n    } else {\n      mat4.copy(this.localMatrix, this.worldMatrix);\n    }\n    const worldMatrix = this.worldMatrix as Float32Array;\n    device.queue.writeBuffer(\n      this.nodeTransformGPUBuffer,\n      0,\n      worldMatrix.buffer,\n      worldMatrix.byteOffset,\n      worldMatrix.byteLength\n    );\n    for (const child of this.children) {\n      child.updateWorldMatrix(device, worldMatrix);\n    }\n  }\n\n  traverse(fn: (n: GLTFNode, ...args) => void) {\n    fn(this);\n    for (const child of this.children) {\n      child.traverse(fn);\n    }\n  }\n\n  renderDrawables(\n    passEncoder: GPURenderPassEncoder,\n    bindGroups: GPUBindGroup[]\n  ) {\n    if (this.drawables !== undefined) {\n      for (const drawable of this.drawables) {\n        if (this.skin) {\n          drawable.render(passEncoder, [\n            ...bindGroups,\n            this.nodeTransformBindGroup,\n            this.skin.skinBindGroup,\n          ]);\n        } else {\n          drawable.render(passEncoder, [\n            ...bindGroups,\n            this.nodeTransformBindGroup,\n          ]);\n        }\n      }\n    }\n    // Render any of its children\n    for (const child of this.children) {\n      child.renderDrawables(passEncoder, bindGroups);\n    }\n  }\n\n  private addChild(child: GLTFNode) {\n    this.children.push(child);\n  }\n\n  private removeChild(child: GLTFNode) {\n    const ndx = this.children.indexOf(child);\n    this.children.splice(ndx, 1);\n  }\n}\n\nexport class GLTFScene {\n  nodes?: number[];\n  root: GLTFNode;\n  name?: string;\n\n  constructor(\n    device: GPUDevice,\n    nodeTransformBGL: GPUBindGroupLayout,\n    baseScene: Scene\n  ) {\n    this.nodes = baseScene.nodes;\n    this.name = baseScene.name;\n    this.root = new GLTFNode(\n      device,\n      nodeTransformBGL,\n      new BaseTransformation(),\n      baseScene.name\n    );\n  }\n}\n\nexport class GLTFSkin {\n  // Nodes of the skin's joints\n  // [5, 2, 3] means our joint info is at nodes 5, 2, and 3\n  joints: number[];\n  // Bind Group for this skin's uniform buffer\n  skinBindGroup: GPUBindGroup;\n  // Static bindGroupLayout shared across all skins\n  // In a larger shader with more properties, certain bind groups\n  // would likely have to be combined due to device limitations in the number of bind groups\n  // allowed within a shader\n  // Inverse bind matrices parsed from the accessor\n  private inverseBindMatrices: Float32Array;\n  private jointMatricesUniformBuffer: GPUBuffer;\n  private inverseBindMatricesUniformBuffer: GPUBuffer;\n  static skinBindGroupLayout: GPUBindGroupLayout;\n\n  static createSharedBindGroupLayout(device: GPUDevice) {\n    this.skinBindGroupLayout = device.createBindGroupLayout({\n      label: 'StaticGLTFSkin.bindGroupLayout',\n      entries: [\n        // Holds the initial joint matrices buffer\n        {\n          binding: 0,\n          buffer: {\n            type: 'read-only-storage',\n          },\n          visibility: GPUShaderStage.VERTEX,\n        },\n        // Holds the inverse bind matrices buffer\n        {\n          binding: 1,\n          buffer: {\n            type: 'read-only-storage',\n          },\n          visibility: GPUShaderStage.VERTEX,\n        },\n      ],\n    });\n  }\n\n  // For the sake of simplicity and easier debugging, we're going to convert our skin gpu accessor to a\n  // float32array, which should be performant enough for this example since there is only one skin (again, this)\n  // is not a comprehensive gltf parser\n  constructor(\n    device: GPUDevice,\n    inverseBindMatricesAccessor: GLTFAccessor,\n    joints: number[]\n  ) {\n    if (\n      inverseBindMatricesAccessor.componentType !==\n        GLTFDataComponentType.FLOAT ||\n      inverseBindMatricesAccessor.byteStride !== 64\n    ) {\n      throw Error(\n        `This skin's provided accessor does not access a mat4x4<f32> matrix, or does not access the provided mat4x4<f32> data correctly`\n      );\n    }\n    // NOTE: Come back to this uint8array to float32array conversion in case it is incorrect\n    this.inverseBindMatrices = new Float32Array(\n      inverseBindMatricesAccessor.view.view.buffer,\n      inverseBindMatricesAccessor.view.view.byteOffset,\n      inverseBindMatricesAccessor.view.view.byteLength / 4\n    );\n    this.joints = joints;\n    const skinGPUBufferUsage: GPUBufferDescriptor = {\n      size: Float32Array.BYTES_PER_ELEMENT * 16 * joints.length,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    };\n    this.jointMatricesUniformBuffer = device.createBuffer(skinGPUBufferUsage);\n    this.inverseBindMatricesUniformBuffer =\n      device.createBuffer(skinGPUBufferUsage);\n    device.queue.writeBuffer(\n      this.inverseBindMatricesUniformBuffer,\n      0,\n      this.inverseBindMatrices\n    );\n    this.skinBindGroup = device.createBindGroup({\n      layout: GLTFSkin.skinBindGroupLayout,\n      label: 'StaticGLTFSkin.bindGroup',\n      entries: [\n        {\n          binding: 0,\n          resource: {\n            buffer: this.jointMatricesUniformBuffer,\n          },\n        },\n        {\n          binding: 1,\n          resource: {\n            buffer: this.inverseBindMatricesUniformBuffer,\n          },\n        },\n      ],\n    });\n  }\n\n  update(device: GPUDevice, currentNodeIndex: number, nodes: GLTFNode[]) {\n    const globalWorldInverse = mat4.inverse(\n      nodes[currentNodeIndex].worldMatrix\n    );\n    for (let j = 0; j < this.joints.length; j++) {\n      const joint = this.joints[j];\n      const dstMatrix: Mat4 = mat4.identity();\n      mat4.multiply(globalWorldInverse, nodes[joint].worldMatrix, dstMatrix);\n      const toWrite = dstMatrix as Float32Array;\n      device.queue.writeBuffer(\n        this.jointMatricesUniformBuffer,\n        j * 64,\n        toWrite.buffer,\n        toWrite.byteOffset,\n        toWrite.byteLength\n      );\n    }\n  }\n}\n\n// Upload a GLB model, parse its JSON and Binary components, and create the requisite GPU resources\n// to render them. NOTE: Not extensible to all GLTF contexts at this point in time\nexport const convertGLBToJSONAndBinary = async (\n  buffer: ArrayBuffer,\n  device: GPUDevice\n): Promise<TempReturn> => {\n  // Binary GLTF layout: https://cdn.willusher.io/webgpu-0-to-gltf/glb-layout.svg\n  const jsonHeader = new DataView(buffer, 0, 20);\n  validateGLBHeader(jsonHeader);\n\n  // Length of the jsonChunk found at jsonHeader[12 - 15]\n  const jsonChunkLength = jsonHeader.getUint32(12, true);\n\n  // Parse the JSON chunk of the glB file to a JSON object\n  const jsonChunk: GlTf = JSON.parse(\n    new TextDecoder('utf-8').decode(new Uint8Array(buffer, 20, jsonChunkLength))\n  );\n\n  console.log(jsonChunk);\n  // Binary data located after jsonChunk\n  const binaryHeader = new Uint32Array(buffer, 20 + jsonChunkLength, 2);\n  validateBinaryHeader(binaryHeader);\n\n  const binaryChunk = new GLTFBuffer(\n    buffer,\n    28 + jsonChunkLength,\n    binaryHeader[0]\n  );\n\n  //Const populate missing properties of jsonChunk\n  for (const accessor of jsonChunk.accessors) {\n    accessor.byteOffset = accessor.byteOffset ?? 0;\n    accessor.normalized = accessor.normalized ?? false;\n  }\n\n  for (const bufferView of jsonChunk.bufferViews) {\n    bufferView.byteOffset = bufferView.byteOffset ?? 0;\n  }\n\n  if (jsonChunk.samplers) {\n    for (const sampler of jsonChunk.samplers) {\n      sampler.wrapS = sampler.wrapS ?? 10497; //GL.REPEAT\n      sampler.wrapT = sampler.wrapT ?? 10947; //GL.REPEAT\n    }\n  }\n\n  //Mark each accessor with its intended usage within the vertexShader.\n  //Often necessary due to infrequencey with which the BufferView target field is populated.\n  for (const mesh of jsonChunk.meshes) {\n    for (const primitive of mesh.primitives) {\n      if ('indices' in primitive) {\n        const accessor = jsonChunk.accessors[primitive.indices];\n        jsonChunk.accessors[primitive.indices].bufferViewUsage |=\n          GPUBufferUsage.INDEX;\n        jsonChunk.bufferViews[accessor.bufferView].usage |=\n          GPUBufferUsage.INDEX;\n      }\n      for (const attribute of Object.values(primitive.attributes)) {\n        const accessor = jsonChunk.accessors[attribute];\n        jsonChunk.accessors[attribute].bufferViewUsage |= GPUBufferUsage.VERTEX;\n        jsonChunk.bufferViews[accessor.bufferView].usage |=\n          GPUBufferUsage.VERTEX;\n      }\n    }\n  }\n\n  // Create GLTFBufferView objects for all the buffer views in the glTF file\n  const bufferViews: GLTFBufferView[] = [];\n  for (let i = 0; i < jsonChunk.bufferViews.length; ++i) {\n    bufferViews.push(new GLTFBufferView(binaryChunk, jsonChunk.bufferViews[i]));\n  }\n\n  const accessors: GLTFAccessor[] = [];\n  for (let i = 0; i < jsonChunk.accessors.length; ++i) {\n    const accessorInfo = jsonChunk.accessors[i];\n    const viewID = accessorInfo['bufferView'];\n    accessors.push(new GLTFAccessor(bufferViews[viewID], accessorInfo));\n  }\n  // Load the first mesh\n  const meshes: GLTFMesh[] = [];\n  for (let i = 0; i < jsonChunk.meshes.length; i++) {\n    const mesh = jsonChunk.meshes[i];\n    const meshPrimitives: GLTFPrimitive[] = [];\n    for (let j = 0; j < mesh.primitives.length; ++j) {\n      const prim = mesh.primitives[j];\n      let topology = prim['mode'];\n      // Default is triangles if mode specified\n      if (topology === undefined) {\n        topology = GLTFRenderMode.TRIANGLES;\n      }\n      if (\n        topology != GLTFRenderMode.TRIANGLES &&\n        topology != GLTFRenderMode.TRIANGLE_STRIP\n      ) {\n        throw Error(`Unsupported primitive mode ${prim['mode']}`);\n      }\n\n      const primitiveAttributeMap = {};\n      const attributes = [];\n      if (jsonChunk['accessors'][prim['indices']] !== undefined) {\n        const indices = accessors[prim['indices']];\n        primitiveAttributeMap['INDICES'] = indices;\n      }\n\n      // Loop through all the attributes and store within our attributeMap\n      for (const attr in prim['attributes']) {\n        const accessor = accessors[prim['attributes'][attr]];\n        primitiveAttributeMap[attr] = accessor;\n        if (accessor.structureType > 3) {\n          throw Error(\n            'Vertex attribute accessor accessed an unsupported data type for vertex attribute'\n          );\n        }\n        attributes.push(attr);\n      }\n      meshPrimitives.push(\n        new GLTFPrimitive(topology, primitiveAttributeMap, attributes)\n      );\n    }\n    meshes.push(new GLTFMesh(mesh.name, meshPrimitives));\n  }\n\n  const skins: GLTFSkin[] = [];\n  for (const skin of jsonChunk.skins) {\n    const inverseBindMatrixAccessor = accessors[skin.inverseBindMatrices];\n    inverseBindMatrixAccessor.view.addUsage(\n      GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST\n    );\n    inverseBindMatrixAccessor.view.needsUpload = true;\n  }\n\n  // Upload the buffer views used by mesh\n  for (let i = 0; i < bufferViews.length; ++i) {\n    if (bufferViews[i].needsUpload) {\n      bufferViews[i].upload(device);\n    }\n  }\n\n  GLTFSkin.createSharedBindGroupLayout(device);\n  for (const skin of jsonChunk.skins) {\n    const inverseBindMatrixAccessor = accessors[skin.inverseBindMatrices];\n    const joints = skin.joints;\n    skins.push(new GLTFSkin(device, inverseBindMatrixAccessor, joints));\n  }\n\n  const nodes: GLTFNode[] = [];\n\n  // Access each node. If node references a mesh, add mesh to that node\n  const nodeUniformsBindGroupLayout = device.createBindGroupLayout({\n    label: 'NodeUniforms.bindGroupLayout',\n    entries: [\n      {\n        binding: 0,\n        buffer: {\n          type: 'uniform',\n        },\n        visibility: GPUShaderStage.VERTEX,\n      },\n    ],\n  });\n  for (const currNode of jsonChunk.nodes) {\n    const baseTransformation = new BaseTransformation(\n      currNode.translation,\n      currNode.rotation,\n      currNode.scale\n    );\n    const nodeToCreate = new GLTFNode(\n      device,\n      nodeUniformsBindGroupLayout,\n      baseTransformation,\n      currNode.name,\n      skins[currNode.skin]\n    );\n    const meshToAdd = meshes[currNode.mesh];\n    if (meshToAdd) {\n      nodeToCreate.drawables.push(meshToAdd);\n    }\n    nodes.push(nodeToCreate);\n  }\n\n  // Assign each node its children\n  nodes.forEach((node, idx) => {\n    const children = jsonChunk.nodes[idx].children;\n    if (children) {\n      children.forEach((childIdx) => {\n        const child = nodes[childIdx];\n        child.setParent(node);\n      });\n    }\n  });\n\n  const scenes: GLTFScene[] = [];\n\n  for (const jsonScene of jsonChunk.scenes) {\n    const scene = new GLTFScene(device, nodeUniformsBindGroupLayout, jsonScene);\n    const sceneChildren = scene.nodes;\n    sceneChildren.forEach((childIdx) => {\n      const child = nodes[childIdx];\n      child.setParent(scene.root);\n    });\n    scenes.push(scene);\n  }\n  return {\n    meshes,\n    nodes,\n    scenes,\n    skins,\n  };\n};\n"},6370:function(e,n){"use strict";n.Z="import { Mat4 } from 'wgpu-matrix';\nimport { GLTFNode } from './glbUtils';\n\n/* Sourced from https://github.com/bwasty/gltf-loader-ts/blob/master/source/gltf.ts */\n/* License for use can be found here: https://github.com/bwasty/gltf-loader-ts/blob/master/LICENSE */\n/* Comments and types have been excluded from original source for sake of cleanliness and brevity */\nexport type GlTfId = number;\n\nexport interface AccessorSparseIndices {\n  bufferView: GlTfId;\n  byteOffset?: number;\n  componentType: 5121 | 5123 | 5125 | number;\n}\n\nexport interface AccessorSparseValues {\n  bufferView: GlTfId;\n  byteOffset?: number;\n}\n\nexport interface AccessorSparse {\n  count: number;\n  indices: AccessorSparseIndices;\n  values: AccessorSparseValues;\n}\n\nexport interface Accessor {\n  bufferView?: GlTfId;\n  bufferViewUsage?: 34962 | 34963 | number;\n  byteOffset?: number;\n  componentType: 5120 | 5121 | 5122 | 5123 | 5125 | 5126 | number;\n  normalized?: boolean;\n  count: number;\n  type: 'SCALAR' | 'VEC2' | 'VEC3' | 'VEC4' | 'MAT2' | 'MAT3' | 'MAT4' | string;\n  max?: number[];\n  min?: number[];\n  sparse?: AccessorSparse;\n  name?: string;\n}\n\nexport interface AnimationChannelTarget {\n  node?: GlTfId;\n  path: 'translation' | 'rotation' | 'scale' | 'weights' | string;\n}\n\nexport interface AnimationChannel {\n  sampler: GlTfId;\n  target: AnimationChannelTarget;\n}\n\nexport interface AnimationSampler {\n  input: GlTfId;\n  interpolation?: 'LINEAR' | 'STEP' | 'CUBICSPLINE' | string;\n  output: GlTfId;\n}\n\nexport interface Animation {\n  channels: AnimationChannel[];\n  samplers: AnimationSampler[];\n  name?: string;\n}\n\nexport interface Asset {\n  copyright?: string;\n  generator?: string;\n  version: string;\n  minVersion?: string;\n}\n\nexport interface Buffer {\n  uri?: string;\n  byteLength: number;\n  name?: string;\n}\n\nexport interface BufferView {\n  buffer: GlTfId;\n  byteOffset?: number;\n  byteLength: number;\n  byteStride?: number;\n  target?: 34962 | 34963 | number;\n  name?: string;\n  usage?: number;\n}\n\nexport interface CameraOrthographic {\n  xmag: number;\n  ymag: number;\n  zfar: number;\n  znear: number;\n}\n\nexport interface CameraPerspective {\n  aspectRatio?: number;\n  yfov: number;\n  zfar?: number;\n  znear: number;\n}\n\nexport interface Camera {\n  orthographic?: CameraOrthographic;\n  perspective?: CameraPerspective;\n  type: 'perspective' | 'orthographic' | string;\n  name?: string;\n}\n\nexport interface Image {\n  uri?: string;\n  mimeType?: 'image/jpeg' | 'image/png' | string;\n  bufferView?: GlTfId;\n  name?: string;\n}\n\nexport interface TextureInfo {\n  index: GlTfId;\n  texCoord?: number;\n}\n\nexport interface MaterialPbrMetallicRoughness {\n  baseColorFactor?: number[];\n  baseColorTexture?: TextureInfo;\n  metallicFactor?: number;\n  roughnessFactor?: number;\n  metallicRoughnessTexture?: TextureInfo;\n}\nexport interface MaterialNormalTextureInfo {\n  index?: number;\n  texCoord?: number;\n  scale?: number;\n}\nexport interface MaterialOcclusionTextureInfo {\n  index?: number;\n  texCoord?: number;\n  strength?: number;\n}\n\nexport interface Material {\n  name?: string;\n  pbrMetallicRoughness?: MaterialPbrMetallicRoughness;\n  normalTexture?: MaterialNormalTextureInfo;\n  occlusionTexture?: MaterialOcclusionTextureInfo;\n  emissiveTexture?: TextureInfo;\n  emissiveFactor?: number[];\n  alphaMode?: 'OPAQUE' | 'MASK' | 'BLEND' | string;\n  alphaCutoff?: number;\n  doubleSided?: boolean;\n}\n\nexport interface MeshPrimitive {\n  attributes: {\n    [k: string]: GlTfId;\n  };\n  indices?: GlTfId;\n  material?: GlTfId;\n  mode?: 0 | 1 | 2 | 3 | 4 | 5 | 6 | number;\n  targets?: {\n    [k: string]: GlTfId;\n  }[];\n}\n\nexport interface Mesh {\n  primitives: MeshPrimitive[];\n  weights?: number[];\n  name?: string;\n}\n\nexport interface Node {\n  camera?: GlTfId;\n  children?: GlTfId[];\n  skin?: GlTfId;\n  matrix?: number[];\n  worldTransformationMatrix?: Mat4;\n  mesh?: GlTfId;\n  rotation?: number[];\n  scale?: number[];\n  translation?: number[];\n  weights?: number[];\n  name?: string;\n}\n\nexport interface Sampler {\n  magFilter?: 9728 | 9729 | number;\n  minFilter?: 9728 | 9729 | 9984 | 9985 | 9986 | 9987 | number;\n  wrapS?: 33071 | 33648 | 10497 | number;\n  wrapT?: 33071 | 33648 | 10497 | number;\n  name?: string;\n}\n\nexport interface Scene {\n  nodes?: GlTfId[];\n  name?: string;\n  root?: GLTFNode;\n}\nexport interface Skin {\n  inverseBindMatrices?: GlTfId;\n  skeleton?: GlTfId;\n  joints: GlTfId[];\n  name?: string;\n}\n\nexport interface Texture {\n  sampler?: GlTfId;\n  source?: GlTfId;\n  name?: string;\n}\n\nexport interface GlTf {\n  extensionsUsed?: string[];\n  extensionsRequired?: string[];\n  accessors?: Accessor[];\n  animations?: Animation[];\n  asset: Asset;\n  buffers?: Buffer[];\n  bufferViews?: BufferView[];\n  cameras?: Camera[];\n  images?: Image[];\n  materials?: Material[];\n  meshes?: Mesh[];\n  nodes?: Node[];\n  samplers?: Sampler[];\n  scene?: GlTfId;\n  scenes?: Scene[];\n  skins?: Skin[];\n  textures?: Texture[];\n}\n"},2624:function(e,n){"use strict";n.Z="struct VertexInput {\n  @location(0) vert_pos: vec2<f32>,\n  @location(1) joints: vec4<u32>,\n  @location(2) weights: vec4<f32>\n}\n\nstruct VertexOutput {\n  @builtin(position) Position: vec4<f32>,\n  @location(0) world_pos: vec3<f32>,\n  @location(1) joints: vec4<f32>,\n  @location(2) weights: vec4<f32>,\n}\n\nstruct CameraUniforms {\n  projMatrix: mat4x4f,\n  viewMatrix: mat4x4f,\n  modelMatrix: mat4x4f,\n}\n\nstruct GeneralUniforms {\n  render_mode: u32,\n  skin_mode: u32,\n}\n\n@group(0) @binding(0) var<uniform> camera_uniforms: CameraUniforms;\n@group(1) @binding(0) var<uniform> general_uniforms: GeneralUniforms;\n@group(2) @binding(0) var<storage, read> joint_matrices: array<mat4x4<f32>>;\n@group(2) @binding(1) var<storage, read> inverse_bind_matrices: array<mat4x4<f32>>;\n\n@vertex\nfn vertexMain(input: VertexInput) -> VertexOutput {\n  var output: VertexOutput;\n  var bones = vec4<f32>(0.0, 0.0, 0.0, 0.0);\n  let position = vec4<f32>(input.vert_pos.x, input.vert_pos.y, 0.0, 1.0);\n  // Get relevant 4 bone matrices\n  let joint0 = joint_matrices[input.joints[0]] * inverse_bind_matrices[input.joints[0]];\n  let joint1 = joint_matrices[input.joints[1]] * inverse_bind_matrices[input.joints[1]];\n  let joint2 = joint_matrices[input.joints[2]] * inverse_bind_matrices[input.joints[2]];\n  let joint3 = joint_matrices[input.joints[3]] * inverse_bind_matrices[input.joints[3]];\n  // Compute influence of joint based on weight\n  let skin_matrix = \n    joint0 * input.weights[0] +\n    joint1 * input.weights[1] +\n    joint2 * input.weights[2] +\n    joint3 * input.weights[3];\n  // Bone transformed mesh\n  output.Position = select(\n    camera_uniforms.projMatrix * camera_uniforms.viewMatrix * camera_uniforms.modelMatrix * position,\n    camera_uniforms.projMatrix * camera_uniforms.viewMatrix * camera_uniforms.modelMatrix * skin_matrix * position,\n    general_uniforms.skin_mode == 0\n  );\n\n  //Get unadjusted world coordinates\n  output.world_pos = position.xyz;\n  output.joints = vec4<f32>(f32(input.joints.x), f32(input.joints.y), f32(input.joints.z), f32(input.joints.w));\n  output.weights = input.weights;\n  return output;\n}\n\n\n@fragment\nfn fragmentMain(input: VertexOutput) -> @location(0) vec4<f32> {\n  switch general_uniforms.render_mode {\n    case 1: {\n      return input.joints;\n    }\n    case 2: {\n      return input.weights;\n    }\n    default: {\n      return vec4<f32>(255.0, 0.0, 1.0, 1.0); \n    }\n  }\n}"},6270:function(e,n){"use strict";n.Z="/* eslint-disable prettier/prettier */\nexport const gridVertices = new Float32Array([\n  // B0\n  0,  1,  // 0 \n  0, -1,  // 1\n  // CONNECTOR\n  2,  1,  // 2\n  2, -1,  // 3\n  // B1\n  4,  1,  // 4\n  4, -1,  // 5\n  // CONNECTOR\n  6,  1,  // 6\n  6, -1,  // 7\n  // B2\n  8,  1,  // 8\n  8, -1, // 9,\n  // CONNECTOR\n  10, 1, //10\n  10, -1, //11\n  // B3\n  12, 1, //12\n  12, -1, //13\n]);\n\n// Representing the indice of four bones that can influence each vertex\nexport const gridJoints = new Uint32Array([\n  0, 0, 0, 0,  // Vertex 0 is influenced by bone 0\n  0, 0, 0, 0,  // 1\n  0, 1, 0, 0,  // 2\n  0, 1, 0, 0,  // 3\n  1, 0, 0, 0,  // 4\n  1, 0, 0, 0,  // 5\n  1, 2, 0, 0,  // Vertex 6 is influenced by bone 1 and bone 2\n  1, 2, 0, 0,  // 7\n  2, 0, 0, 0,  // 8\n  2, 0, 0, 0,  // 9\n  1, 2, 3, 0,  //10\n  1, 2, 3, 0,  //11\n  2, 3, 0, 0,  //12\n  2, 3, 0, 0,  //13\n])\n\n// The weights applied when ve\nexport const gridWeights = new Float32Array([\n  // B0\n  1, 0, 0, 0,  // 0\n  1, 0, 0, 0,  // 1\n  // CONNECTOR\n .5,.5, 0, 0,  // 2\n .5,.5, 0, 0,  // 3\n  // B1\n  1, 0, 0, 0,  // 4\n  1, 0, 0, 0,  // 5\n  // CONNECTOR\n .5,.5, 0, 0,  // 6\n .5,.5, 0, 0,  // 7\n  // B2\n  1, 0, 0, 0,  // 8\n  1, 0, 0, 0,  // 9\n   // CONNECTOR\n .5,.5, 0, 0,  // 10\n .5,.5, 0, 0,  // 11\n  // B3\n  1, 0, 0, 0,  // 12\n  1, 0, 0, 0,  // 13\n]);\n\n// Using data above...\n// Vertex 0 is influenced by bone 0 with a weight of 1 \n// Vertex 1 is influenced by bone 1 with a weight of 1\n// Vertex 2 is influenced by bone 0 and 1 with a weight of 0.5 each\n// and so on..\n// Although a vertex can hypothetically be influenced by 4 bones,\n// in this example, we stick to each vertex being infleunced by only two\n// although there can be downstream effects of parent bones influencing child bones\n// that influence their own children\n\nexport const gridIndices = new Uint16Array([\n  // B0\n  0, 1,\n  0, 2,\n  1, 3,\n  // CONNECTOR\n  2, 3, //\n  2, 4,\n  3, 5,\n  // B1\n  4, 5,\n  4, 6,\n  5, 7, \n  // CONNECTOR\n  6, 7,\n  6, 8,\n  7, 9,\n  // B2\n  8, 9,\n  8, 10,\n  9, 11,\n  // CONNECTOR\n  10, 11,\n  10, 12,\n  11, 13,\n  // B3\n  12, 13,\n]);"},9483:function(e,n){"use strict";n.Z="import { gridVertices, gridIndices, gridJoints, gridWeights } from './gridData';\n\n// Uses constant grid data to create appropriately sized GPU Buffers for our skinned grid\nexport const createSkinnedGridBuffers = (device: GPUDevice) => {\n  // Utility function that creates GPUBuffers from data\n  const createBuffer = (\n    data: Float32Array | Uint32Array,\n    type: 'f32' | 'u32'\n  ) => {\n    const buffer = device.createBuffer({\n      size: data.byteLength,\n      usage: GPUBufferUsage.VERTEX,\n      mappedAtCreation: true,\n    });\n    if (type === 'f32') {\n      new Float32Array(buffer.getMappedRange()).set(data);\n    } else {\n      new Uint32Array(buffer.getMappedRange()).set(data);\n    }\n    buffer.unmap();\n    return buffer;\n  };\n  const positionsBuffer = createBuffer(gridVertices, 'f32');\n  const jointsBuffer = createBuffer(gridJoints, 'u32');\n  const weightsBuffer = createBuffer(gridWeights, 'f32');\n  const indicesBuffer = device.createBuffer({\n    size: Uint16Array.BYTES_PER_ELEMENT * gridIndices.length,\n    usage: GPUBufferUsage.INDEX,\n    mappedAtCreation: true,\n  });\n  new Uint16Array(indicesBuffer.getMappedRange()).set(gridIndices);\n  indicesBuffer.unmap();\n\n  return {\n    positions: positionsBuffer,\n    joints: jointsBuffer,\n    weights: weightsBuffer,\n    indices: indicesBuffer,\n  };\n};\n\nexport const createSkinnedGridRenderPipeline = (\n  device: GPUDevice,\n  presentationFormat: GPUTextureFormat,\n  vertexShader: string,\n  fragmentShader: string,\n  bgLayouts: GPUBindGroupLayout[]\n) => {\n  const pipeline = device.createRenderPipeline({\n    label: 'SkinnedGridRenderer',\n    layout: device.createPipelineLayout({\n      label: `SkinnedGridRenderer.pipelineLayout`,\n      bindGroupLayouts: bgLayouts,\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        label: `SkinnedGridRenderer.vertexShader`,\n        code: vertexShader,\n      }),\n      entryPoint: 'vertexMain',\n      buffers: [\n        // Vertex Positions (positions)\n        {\n          arrayStride: Float32Array.BYTES_PER_ELEMENT * 2,\n          attributes: [\n            {\n              format: 'float32x2',\n              offset: 0,\n              shaderLocation: 0,\n            },\n          ],\n        },\n        // Bone Indices (joints)\n        {\n          arrayStride: Uint32Array.BYTES_PER_ELEMENT * 4,\n          attributes: [\n            {\n              format: 'uint32x4',\n              offset: 0,\n              shaderLocation: 1,\n            },\n          ],\n        },\n        // Bone Weights (weights)\n        {\n          arrayStride: Float32Array.BYTES_PER_ELEMENT * 4,\n          attributes: [\n            {\n              format: 'float32x4',\n              offset: 0,\n              shaderLocation: 2,\n            },\n          ],\n        },\n      ],\n    },\n    fragment: {\n      module: device.createShaderModule({\n        label: `SkinnedGridRenderer.fragmentShader`,\n        code: fragmentShader,\n      }),\n      entryPoint: 'fragmentMain',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: 'line-list',\n    },\n  });\n  return pipeline;\n};\n"},134:function(e,n){"use strict";n.Z="@group(0) @binding(0) var mySampler : sampler;\n@group(0) @binding(1) var myTexture : texture_2d<f32>;\n\nstruct VertexOutput {\n  @builtin(position) Position : vec4<f32>,\n  @location(0) fragUV : vec2<f32>,\n}\n\n@vertex\nfn vert_main(@builtin(vertex_index) VertexIndex : u32) -> VertexOutput {\n  const pos = array(\n    vec2( 1.0,  1.0),\n    vec2( 1.0, -1.0),\n    vec2(-1.0, -1.0),\n    vec2( 1.0,  1.0),\n    vec2(-1.0, -1.0),\n    vec2(-1.0,  1.0),\n  );\n\n  const uv = array(\n    vec2(1.0, 0.0),\n    vec2(1.0, 1.0),\n    vec2(0.0, 1.0),\n    vec2(1.0, 0.0),\n    vec2(0.0, 1.0),\n    vec2(0.0, 0.0),\n  );\n\n  var output : VertexOutput;\n  output.Position = vec4(pos[VertexIndex], 0.0, 1.0);\n  output.fragUV = uv[VertexIndex];\n  return output;\n}\n\n@fragment\nfn frag_main(@location(0) fragUV : vec2<f32>) -> @location(0) vec4<f32> {\n  return textureSample(myTexture, mySampler, fragUV);\n}\n"}}]);