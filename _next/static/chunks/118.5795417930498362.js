(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[118],{5671:function(e,n,t){"use strict";t.d(n,{Tl:function(){return d},hu:function(){return p}});var r=t(5893),a=t(9008),i=t.n(a),o=t(1163),s=t(7294),l=t(9147),u=t.n(l);t(7319);let c=e=>{let n=(0,s.useRef)(null),a=(0,s.useMemo)(()=>e.sources.map(e=>{let{name:n,contents:a}=e;return{name:n,...function(e){let n;let a=null;{a=document.createElement("div");let i=t(4631);n=i(a,{lineNumbers:!0,lineWrapping:!0,theme:"monokai",readOnly:!0})}return{Container:function(t){return(0,r.jsx)("div",{...t,children:(0,r.jsx)("div",{ref(t){a&&t&&(t.appendChild(a),n.setOption("value",e))}})})}}}(a)}}),e.sources),l=(0,s.useRef)(null),c=(0,s.useMemo)(()=>{if(e.gui){let n=t(4376);return new n.GUI({autoPlace:!1})}},[]),d=(0,s.useRef)(null),p=(0,s.useMemo)(()=>{if(e.stats){let n=t(2792);return new n}},[]),m=(0,o.useRouter)(),g=m.asPath.match(/#([a-zA-Z0-9\.\/]+)/),[h,f]=(0,s.useState)(null),[x,v]=(0,s.useState)(null);return(0,s.useEffect)(()=>{if(g?v(g[1]):v(a[0].name),c&&l.current)for(l.current.appendChild(c.domElement);c.__controllers.length>0;)c.__controllers[0].remove();p&&d.current&&(p.dom.style.position="absolute",p.showPanel(1),d.current.appendChild(p.dom));let t={active:!0},r=()=>{t.active=!1};try{let i=n.current;if(!i)throw Error("The canvas is not available");let o=e.init({canvas:i,pageState:t,gui:c,stats:p});o instanceof Promise&&o.catch(e=>{console.error(e),f(e)})}catch(s){console.error(s),f(s)}return r},[]),(0,r.jsxs)("main",{children:[(0,r.jsxs)(i(),{children:[(0,r.jsx)("style",{dangerouslySetInnerHTML:{__html:"\n            .CodeMirror {\n              height: auto !important;\n              margin: 1em 0;\n            }\n\n            .CodeMirror-scroll {\n              height: auto !important;\n              overflow: visible !important;\n            }\n          "}}),(0,r.jsx)("title",{children:"".concat(e.name," - WebGPU Samples")}),(0,r.jsx)("meta",{name:"description",content:e.description}),(0,r.jsx)("meta",{httpEquiv:"origin-trial",content:e.originTrial})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h1",{children:e.name}),(0,r.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/".concat("webgpu/webgpu-samples","/tree/main/").concat(e.filename),children:"See it on Github!"}),(0,r.jsx)("p",{children:e.description}),h?(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("p",{children:"Something went wrong. Do your browser and device support WebGPU?"}),(0,r.jsx)("p",{children:"".concat(h)})]}):null]}),(0,r.jsxs)("div",{className:u().canvasContainer,children:[(0,r.jsx)("div",{style:{position:"absolute",left:10},ref:d}),(0,r.jsx)("div",{style:{position:"absolute",right:10},ref:l}),(0,r.jsx)("canvas",{ref:n})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("nav",{className:u().sourceFileNav,children:(0,r.jsx)("ul",{children:a.map((e,n)=>(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"#".concat(e.name),"data-active":x==e.name,onClick(){v(e.name)},children:e.name})},n))})}),a.map((e,n)=>(0,r.jsx)(e.Container,{className:u().sourceFileContainer,"data-active":x==e.name},n))]})]})},d=e=>(0,r.jsx)(c,{...e});function p(e,n){if(!e)throw Error(n)}},7118:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return T}});var r,a,i=t(6416),o=t(5671),s="struct SpaceTransformUniforms {\n  projMatrix: mat4x4f,\n  viewMatrix: mat4x4f,\n  modelMatrix: mat4x4f,\n}\n\nstruct Uniforms_MapInfo {\n  mappingType: u32,\n  lightPosX: f32,\n  lightPosY: f32,\n  lightPosZ: f32,\n  lightIntensity: f32,\n  depthScale: f32,\n  depthLayers: f32,\n}\n\nstruct VertexInput {\n  // Shader assumes the missing 4th float is 1.0\n  @location(0) position : vec4f,\n  @location(1) normal : vec3f,\n  @location(2) uv : vec2f,\n  @location(3) vert_tan: vec3f,\n  @location(4) vert_bitan: vec3f,\n}\n\nstruct VertexOutput {\n  @builtin(position) Position : vec4f,\n  @location(0) normal: vec3f,\n  @location(1) uv : vec2f,\n  // Vertex position in world space\n  @location(2) posWS: vec3f,\n  // Vertex position in tangent space\n  @location(3) posTS: vec3f,\n  // View position in tangent space\n  @location(4) viewTS: vec3f,\n  // Extracted components of our tbn matrix\n  @location(5) tbnTS0: vec3<f32>, \n  @location(6) tbnTS1: vec3<f32>,\n  @location(7) tbnTS2: vec3<f32>,\n}\n\n// Uniforms\n@group(0) @binding(0) var<uniform> spaceTransform : SpaceTransformUniforms;\n@group(0) @binding(1) var<uniform> mapInfo: Uniforms_MapInfo;\n\n// Texture info\n@group(1) @binding(0) var textureSampler: sampler;\n@group(1) @binding(1) var diffuseTexture: texture_2d<f32>;\n@group(1) @binding(2) var normalTexture: texture_2d<f32>;\n@group(1) @binding(3) var depthTexture: texture_2d<f32>;\n\nfn parallax_uv(\n  uv: vec2f, \n  viewDirTS: vec3f, \n  depthSample: f32,\n  depthScale: f32,\n) -> vec2f {\n  if (mapInfo.mappingType == 4) {\n    // Perturb uv coordinates based on depth and camera direction\n    let p = viewDirTS.xy * (depthSample * depthScale) / viewDirTS.z;\n    return uv - p;\n  }\n  // Break up depth space into layers\n  let depthPerLayer = 1.0 / f32(mapInfo.depthLayers);\n  // Start at lowest depth\n  var currentDepth = 0.0;\n  let delta_uv = viewDirTS.xy * depthScale / (viewDirTS.z * mapInfo.depthLayers);\n  var prev_uv = uv;\n  var cur_uv = uv;\n\n  var depthFromTexture = textureSample(depthTexture, textureSampler, cur_uv).r;\n  var prevDepthFromTexture = depthFromTexture;\n  var prevCurrentDepth  = currentDepth;\n  for (var i: u32 = 0; i < 32; i++) {\n    currentDepth += depthPerLayer;\n    prev_uv = cur_uv;\n    cur_uv -= delta_uv;\n    depthFromTexture = textureSample(depthTexture, textureSampler, cur_uv).r;\n    // Determine whether current depth is greater than depth map\n    // Once we reach a certain threshold, we stop updating cur_uv\n    cur_uv = select(cur_uv, prev_uv, depthFromTexture < currentDepth);\n    prevDepthFromTexture = select(depthFromTexture, prevDepthFromTexture, prevDepthFromTexture < currentDepth);\n    prevCurrentDepth = select(currentDepth, prevCurrentDepth, prevDepthFromTexture < currentDepth);\n  }\n  return cur_uv;\n}\n\nfn when_greater(v1: f32, v2: f32) -> f32 {\n  return max(sign(v1 - v2), 0.0);\n}\n\n@vertex\nfn vertexMain(input: VertexInput) -> VertexOutput {\n  var output : VertexOutput;\n  // Create the Model to View Matrix\n  let MV = spaceTransform.viewMatrix * spaceTransform.modelMatrix;\n  // Create the Model to View to Projection Matrix\n  let MVP = spaceTransform.projMatrix * MV;\n  \n  // Get Clip space transforms and pass through values out of the way\n  output.Position = MVP * input.position;\n  output.uv = input.uv;\n  output.normal = input.normal;\n\n  // Multiply pos by modelMatrix to get the vertex/fragment's position in world space\n  output.posWS = vec3f((spaceTransform.modelMatrix * input.position).xyz);\n  \n  var MV3x3 = mat3x3f(\n    MV[0].xyz,\n    MV[1].xyz,\n    MV[2].xyz\n  );\n\n  // Get unit vectors of normal, tangent, and bitangents in model space\n  let vertexTangent = normalize(input.vert_tan);\n  let vertexBitangent = normalize(input.vert_bitan);\n  let vertexNormal = normalize(input.normal);\n\n  // Convert tbn unit vectors to mv space for a model view tbn\n  var tbnTS = transpose(\n    MV3x3 * mat3x3f(\n      vertexTangent,\n      vertexBitangent,\n      vertexNormal\n    )\n  );\n  // Condense to vec3s so they can be passed to fragment shader\n  output.tbnTS0 = tbnTS[0];\n  output.tbnTS1 = tbnTS[1];\n  output.tbnTS2 = tbnTS[2];\n\n  // Get the tangent space position of the vertex\n  output.posTS = tbnTS * (MV * input.position).xyz;\n  // Get the tangent space position of the camera view\n  output.viewTS = tbnTS * vec3f(0.0, 0.0, 0.0);\n\n  return output;\n}\n\n@fragment\nfn fragmentMain(input: VertexOutput) -> @location(0) vec4f {\n  // Reconstruct tbnTS\n  let tbnTS = mat3x3f(\n    input.tbnTS0,\n    input.tbnTS1,\n    input.tbnTS2,\n  );\n\n  // Get direction of view in tangent space\n  let viewDirTS = normalize(input.viewTS - input.posTS);\n\n  // Get position, direction, and distance of light in tangent space (no need to multiply by model matrix as there is no model)\n  let lightPosVS = spaceTransform.viewMatrix * vec4f(mapInfo.lightPosX, mapInfo.lightPosY, mapInfo.lightPosZ, 1.0);\n  let lightPosTS = tbnTS * lightPosVS.xyz;\n  let lightDirTS = normalize(lightPosTS - input.posTS);\n  let lightDistanceTS = distance(input.posTS, lightPosTS);\n\n  let depthMap = textureSample(depthTexture, textureSampler, input.uv); \n\n  let uv = select(\n    parallax_uv(input.uv, viewDirTS, depthMap.r, mapInfo.depthScale),\n    input.uv,\n    mapInfo.mappingType < 4\n  );\n\n  // Get values from textures\n  let diffuseMap = textureSample(diffuseTexture, textureSampler, uv);\n  let normalMap = textureSample(normalTexture, textureSampler, uv);\n\n  // Get normal in tangent space\n  let normalTS = normalize((normalMap.xyz * 2.0) - 1.0);\n  \n  // Calculate diffusion lighting\n  let lightColorIntensity = vec3f(255.0, 255.0, 255.0) * mapInfo.lightIntensity;\n  //How similar is the normal to the lightDirection\n  let diffuseStrength = clamp(\n    dot(normalTS, lightDirTS), 0.0, 1.0\n  );\n  // Strenght inversely proportional to square of distance from light\n  let diffuseLight = (lightColorIntensity * diffuseStrength) / (lightDistanceTS * lightDistanceTS);\n\n  switch (mapInfo.mappingType) {\n    // Output the diffuse texture\n    case 0: {\n      return vec4f(diffuseMap.rgb, 1.0);\n    }\n    // Output the normal map\n    case 1: {\n      return vec4f(normalMap.rgb, 1.0);\n    }\n    // Output the height map\n    case 2: {\n      return vec4f(depthMap.rgb, 1.0);\n    }\n    default: {\n      return vec4f(diffuseMap.rgb * diffuseLight, 1.0);\n    }\n  }\n}";let l=function(e,n){let t=arguments.length>2&&void 0!==arguments[2]&&arguments[2],r=arguments.length>3&&void 0!==arguments[3]&&arguments[3],a=t?GPUBufferUsage.VERTEX|GPUBufferUsage.STORAGE:GPUBufferUsage.VERTEX,i=r?GPUBufferUsage.INDEX|GPUBufferUsage.STORAGE:GPUBufferUsage.INDEX,o=e.createBuffer({size:n.vertices.byteLength,usage:a,mappedAtCreation:!0});new Float32Array(o.getMappedRange()).set(n.vertices),o.unmap();let s=e.createBuffer({size:n.indices.byteLength,usage:i,mappedAtCreation:!0});return n.indices.byteLength===n.indices.length*Uint16Array.BYTES_PER_ELEMENT?new Uint16Array(s.getMappedRange()).set(n.indices):new Uint32Array(s.getMappedRange()).set(n.indices),s.unmap(),{vertexBuffer:o,indexBuffer:s,indexCount:n.indices.length}},u=(e,n)=>{let t=new Float32Array(e.vertices.buffer,n*e.vertexStride+0,3);return i.R3.fromValues(t[0],t[1],t[2])},c=(e,n)=>{let t=new Float32Array(e.vertices.buffer,n*e.vertexStride+6*Float32Array.BYTES_PER_ELEMENT,2);return i.K4.fromValues(t[0],t[1])},d=function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:1,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1,t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:1,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1,a=arguments.length>4&&void 0!==arguments[4]?arguments[4]:1,o=arguments.length>5&&void 0!==arguments[5]?arguments[5]:1;r=Math.floor(r),a=Math.floor(a),o=Math.floor(o);let s=[],l=[],u=0,c=(e,n,t,r,a,o,c,d,p,m)=>{let g=o/p,h=c/m,f=o/2,x=c/2,v=d/2,b=p+1,y=m+1,S=0,T=i.R3.create(),w=i.R3.create();for(let P=0;P<y;P++){let B=P*h-x;for(let U=0;U<b;U++){let G=U*g-f;T[e]=G*r,T[n]=B*a,T[t]=v,l.push(...T),w[e]=0,w[n]=0,w[t]=d>0?1:-1,l.push(...w),l.push(U/p),l.push(1-P/m),S+=1}}for(let M=0;M<m;M++)for(let E=0;E<p;E++){let V=u+E+b*M,A=u+E+b*(M+1),F=u+(E+1)+b*(M+1),_=u+(E+1)+b*M;s.push(V,A,_),s.push(A,F,_),u+=S}};return c(2,1,0,-1,-1,t,n,e,o,a),c(2,1,0,1,-1,t,n,-e,o,a),c(0,2,1,1,1,e,t,n,r,o),c(0,2,1,1,-1,e,t,-n,r,o),c(0,1,2,1,-1,e,n,t,r,a),c(0,1,2,-1,-1,e,n,-t,r,a),{vertices:l,indices:s}},p=function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:1,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1,t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:1,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1,a=arguments.length>4&&void 0!==arguments[4]?arguments[4]:1,i=arguments.length>5&&void 0!==arguments[5]?arguments[5]:1,o=arguments.length>6&&void 0!==arguments[6]?arguments[6]:"uint16",{vertices:s,indices:l}=d(e,n,t,r,a,i),u=8*Float32Array.BYTES_PER_ELEMENT,c="uint16"===o?new Uint16Array(l):new Uint32Array(l);return{vertices:new Float32Array(s),indices:c,vertexStride:u}},m=function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:1,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1,t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:1,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1,a=arguments.length>4&&void 0!==arguments[4]?arguments[4]:1,o=arguments.length>5&&void 0!==arguments[5]?arguments[5]:1,s=p(e,n,t,r,a,o),l=s.vertexStride/Float32Array.BYTES_PER_ELEMENT,d=s.vertices.length/l,m=Array(d),g=Array(d),h=Array(d);for(let f=0;f<d;f++)m[f]=[0,0,0],g[f]=[0,0,0],h[f]=0;for(let x=0;x<s.indices.length;x+=3){let[v,b,y]=[s.indices[x],s.indices[x+1],s.indices[x+2]],[S,T,w]=[u(s,v),u(s,b),u(s,y)],[P,B,U]=[c(s,v),c(s,b),c(s,y)],G=i.R3.sub(T,S),M=i.R3.sub(w,S),E=i.R3.sub(B,P),V=i.R3.sub(U,P),A=1/(E[0]*V[1]-E[1]*V[0]),F=[A*(V[1]*G[0]-E[1]*M[0]),A*(V[1]*G[1]-E[1]*M[1]),A*(V[1]*G[2]-E[1]*M[2])],_=[A*(-V[0]*G[0]+E[0]*M[0]),A*(-V[0]*G[1]+E[0]*M[1]),A*(-V[0]*G[2]+E[0]*M[2])];m[v]=i.R3.add(m[v],F),g[v]=i.R3.add(g[v],_),m[b]=i.R3.add(m[b],F),g[b]=i.R3.add(g[b],_),m[y]=i.R3.add(m[y],F),g[y]=i.R3.add(g[y],_),h[v]++,h[b]++,h[y]++}for(let R=0;R<m.length;R++)m[R]=i.R3.divScalar(m[R],h[R]),g[R]=i.R3.divScalar(g[R],h[R]);let L=new Float32Array(14*d);for(let D=0;D<d;D++)L.set(s.vertices.subarray(D*l,(D+1)*l),14*D),L.set(m[D],14*D+l),L.set(g[D],14*D+l+3);return{vertices:L,indices:s.indices,vertexStride:s.vertexStride+6*Float32Array.BYTES_PER_ELEMENT}},g=(e,n,t,r,a,i,o)=>{let s=[];for(let l=0;l<e.length;l++)s.push({binding:e[l],visibility:n[l%n.length],[t[l]]:r[l]});let u=o.createBindGroupLayout({label:"".concat(i,".bindGroupLayout"),entries:s}),c=[];for(let d=0;d<a.length;d++){let p=[];for(let m=0;m<a[0].length;m++)p.push({binding:m,resource:a[d][m]});let g=o.createBindGroup({label:"".concat(i,".bindGroup").concat(d),layout:u,entries:p});c.push(g)}return{bindGroups:c,bindGroupLayout:u}},h=e=>{let n=e.split("x"),t=parseInt(n[0].replace(/[^0-9]/g,""))/8,r=t*(void 0!==n[1]?parseInt(n[1]):1);return r},f=e=>{let n=e.reduce((e,n,t)=>{let r={shaderLocation:t,offset:e.arrayStride,format:n},a=e.arrayStride+h(n),i={attributes:[...e.attributes,r],arrayStride:a};return i},{attributes:[],arrayStride:0}),t={arrayStride:n.arrayStride,attributes:n.attributes};return t},x=function(e,n,t,r,a,i,o){let s=arguments.length>7&&void 0!==arguments[7]&&arguments[7],l=arguments.length>8&&void 0!==arguments[8]?arguments[8]:"triangle-list",u=arguments.length>9&&void 0!==arguments[9]?arguments[9]:"back",c={label:"".concat(n,".pipeline"),layout:e.createPipelineLayout({label:"".concat(n,".pipelineLayout"),bindGroupLayouts:t}),vertex:{module:e.createShaderModule({label:"".concat(n,".vertexShader"),code:r}),entryPoint:"vertexMain",buffers:0!==a.length?[f(a)]:[]},fragment:{module:e.createShaderModule({label:"".concat(n,".fragmentShader"),code:i}),entryPoint:"fragmentMain",targets:[{format:o}]},primitive:{topology:l,cullMode:u}};return s&&(c.depthStencil={depthCompare:"less",depthWriteEnabled:!0,format:"depth24plus"}),e.createRenderPipeline(c)},v=(e,n)=>{let t=e.createTexture({size:[n.width,n.height,1],format:"rgba8unorm",usage:GPUTextureUsage.TEXTURE_BINDING|GPUTextureUsage.COPY_DST|GPUTextureUsage.RENDER_ATTACHMENT});return e.queue.copyExternalImageToTexture({source:n},{texture:t},[n.width,n.height]),t};var b="src/sample/normalMap/main.ts";(r=a||(a={}))[r.Spiral=0]="Spiral",r[r.Toybox=1]="Toybox",r[r.BrickWall=2]="BrickWall";let y=async e=>{let n,r,o,u,c,d,p,h,{canvas:f,pageState:b,gui:y}=e,S=await navigator.gpu.requestAdapter(),T=await S.requestDevice();if(!b.active)return;let w=f.getContext("webgpu"),P=window.devicePixelRatio;f.width=f.clientWidth*P,f.height=f.clientHeight*P;let B=navigator.gpu.getPreferredCanvasFormat();w.configure({device:T,format:B,alphaMode:"premultiplied"});let U={"Bump Mode":"Normal Map",cameraPosX:0,cameraPosY:.8,cameraPosZ:-1.4,lightPosX:1.7,lightPosY:.7,lightPosZ:-1.9,lightIntensity:.02,depthScale:.05,depthLayers:16,Texture:"Spiral","Reset Light"(){}},G=T.createTexture({size:[f.width,f.height],format:"depth24plus",usage:GPUTextureUsage.RENDER_ATTACHMENT}),M=T.createBuffer({size:256,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),E=T.createBuffer({size:7*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST});{let V=await fetch(new t.U(t(3765)).toString()),A=await createImageBitmap(await V.blob());n=v(T,A)}{let F=await fetch(new t.U(t(6465)).toString()),_=await createImageBitmap(await F.blob());r=v(T,_)}{let R=await fetch(new t.U(t(2146)).toString()),L=await createImageBitmap(await R.blob());o=v(T,L)}{let D=await fetch(new t.U(t(2283)).toString()),I=await createImageBitmap(await D.blob());u=v(T,I)}{let C=await fetch(new t.U(t(5784)).toString()),N=await createImageBitmap(await C.blob());c=v(T,N)}{let j=await fetch(new t.U(t(7596)).toString()),Y=await createImageBitmap(await j.blob());d=v(T,Y)}{let O=await fetch(new t.U(t(4334)).toString()),X=await createImageBitmap(await O.blob());p=v(T,X)}{let z=await fetch(new t.U(t(7669)).toString()),k=await createImageBitmap(await z.blob());h=v(T,k)}let H=T.createSampler({magFilter:"linear",minFilter:"linear"}),q={colorAttachments:[{view:void 0,clearValue:{r:0,g:0,b:0,a:1},loadOp:"clear",storeOp:"store"}],depthStencilAttachment:{view:G.createView(),depthClearValue:1,depthLoadOp:"clear",depthStoreOp:"store"}},W=l(T,m(1,1,1)),Z=g([0,1],[GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,GPUShaderStage.FRAGMENT|GPUShaderStage.VERTEX],["buffer","buffer"],[{type:"uniform"},{type:"uniform"}],[[{buffer:M},{buffer:E}]],"Frame",T),$=g([0,1,2,3],[GPUShaderStage.FRAGMENT],["sampler","texture","texture","texture"],[{type:"filtering"},{sampleType:"float"},{sampleType:"float"},{sampleType:"float"}],[[H,n.createView(),r.createView(),o.createView()],[H,n.createView(),u.createView(),c.createView()],[H,d.createView(),p.createView(),h.createView()]],"Surface",T),K=f.width/f.height,J=i._E.perspective(2*Math.PI/5,K,.1,10),Q=()=>{switch(U["Bump Mode"]){case"Diffuse Texture":return 0;case"Normal Texture":return 1;case"Depth Texture":return 2;case"Normal Map":return 3;case"Parallax Scale":return 4;case"Steep Parallax":return 5}},ee=x(T,"NormalMappingRender",[Z.bindGroupLayout,$.bindGroupLayout],s,["float32x3","float32x3","float32x2","float32x3","float32x3"],s,B,!0),en=0,et=()=>{en=a[U.Texture]};y.add(U,"Bump Mode",["Diffuse Texture","Normal Texture","Depth Texture","Normal Map","Parallax Scale","Steep Parallax"]),y.add(U,"Texture",["Spiral","Toybox","BrickWall"]).onChange(et);let er=y.addFolder("Light"),ea=y.addFolder("Depth");er.add(U,"Reset Light").onChange(()=>{ei.setValue(1.7),eo.setValue(.7),es.setValue(-1.9),el.setValue(.02)});let ei=er.add(U,"lightPosX",-5,5).step(.1),eo=er.add(U,"lightPosY",-5,5).step(.1),es=er.add(U,"lightPosZ",-5,5).step(.1),el=er.add(U,"lightIntensity",0,.1).step(.002);ea.add(U,"depthScale",0,.1).step(.01),ea.add(U,"depthLayers",1,32).step(1),requestAnimationFrame(function e(){if(!b.active)return;let n=i._E.lookAt([U.cameraPosX,U.cameraPosY,U.cameraPosZ],[0,0,0],[0,1,0]),t=function(){let e=i._E.create();i._E.identity(e);let n=Date.now()/1e3;return i._E.rotateY(e,-.5*n,e),e}(),r=new Float32Array([...J,...n,...t]),a=Q();T.queue.writeBuffer(M,0,r.buffer,r.byteOffset,r.byteLength),T.queue.writeBuffer(E,0,new Uint32Array([a])),T.queue.writeBuffer(E,4,new Float32Array([U.lightPosX,U.lightPosY,U.lightPosZ,U.lightIntensity,U.depthScale,U.depthLayers])),q.colorAttachments[0].view=w.getCurrentTexture().createView();let o=T.createCommandEncoder(),s=o.beginRenderPass(q);s.setPipeline(ee),s.setBindGroup(0,Z.bindGroups[0]),s.setBindGroup(1,$.bindGroups[en]),s.setVertexBuffer(0,W.vertexBuffer),s.setIndexBuffer(W.indexBuffer,"uint16"),s.drawIndexed(W.indexCount),s.end(),T.queue.submit([o.finish()]),requestAnimationFrame(e)})},S=()=>(0,o.Tl)({name:"Normal Mapping",description:"This example demonstrates multiple different methods that employ fragment shaders to achieve additional perceptual depth on the surface of a cube mesh. Demonstrated methods include normal mapping, parallax mapping, and steep parallax mapping.",gui:!0,init:y,sources:[{name:b.substring(21),contents:"import { mat4 } from 'wgpu-matrix';\nimport { makeSample, SampleInit } from '../../components/SampleLayout';\nimport normalMapWGSL from './normalMap.wgsl';\nimport { createMeshRenderable } from '../../meshes/mesh';\nimport { createBoxMeshWithTangents } from '../../meshes/box';\nimport {\n  createBindGroupDescriptor,\n  create3DRenderPipeline,\n  createTextureFromImage,\n} from './utils';\n\nconst MAT4X4_BYTES = 64;\nenum TextureAtlas {\n  Spiral,\n  Toybox,\n  BrickWall,\n}\n\nconst init: SampleInit = async ({ canvas, pageState, gui }) => {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n  if (!pageState.active) return;\n  const context = canvas.getContext('webgpu') as GPUCanvasContext;\n  const devicePixelRatio = window.devicePixelRatio;\n  canvas.width = canvas.clientWidth * devicePixelRatio;\n  canvas.height = canvas.clientHeight * devicePixelRatio;\n  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n  context.configure({\n    device,\n    format: presentationFormat,\n    alphaMode: 'premultiplied',\n  });\n\n  interface GUISettings {\n    'Bump Mode':\n      | 'Diffuse Texture'\n      | 'Normal Texture'\n      | 'Depth Texture'\n      | 'Normal Map'\n      | 'Parallax Scale'\n      | 'Steep Parallax';\n    cameraPosX: number;\n    cameraPosY: number;\n    cameraPosZ: number;\n    lightPosX: number;\n    lightPosY: number;\n    lightPosZ: number;\n    lightIntensity: number;\n    depthScale: number;\n    depthLayers: number;\n    Texture: string;\n    'Reset Light': () => void;\n  }\n\n  const settings: GUISettings = {\n    'Bump Mode': 'Normal Map',\n    cameraPosX: 0.0,\n    cameraPosY: 0.8,\n    cameraPosZ: -1.4,\n    lightPosX: 1.7,\n    lightPosY: 0.7,\n    lightPosZ: -1.9,\n    lightIntensity: 0.02,\n    depthScale: 0.05,\n    depthLayers: 16,\n    Texture: 'Spiral',\n    'Reset Light': () => {\n      return;\n    },\n  };\n\n  // Create normal mapping resources and pipeline\n  const depthTexture = device.createTexture({\n    size: [canvas.width, canvas.height],\n    format: 'depth24plus',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const uniformBuffer = device.createBuffer({\n    // Buffer holding projection, view, and model matrices plus padding bytes\n    size: MAT4X4_BYTES * 4,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const mapMethodBuffer = device.createBuffer({\n    // Buffer holding mapping type, light uniforms, and depth uniforms\n    size: Float32Array.BYTES_PER_ELEMENT * 7,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  // Fetch the image and upload it into a GPUTexture.\n  let woodDiffuseTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/wood_diffuse.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    woodDiffuseTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let spiralNormalTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/spiral_normal.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    spiralNormalTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let spiralHeightTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/spiral_height.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    spiralHeightTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let toyboxNormalTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/toybox_normal.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    toyboxNormalTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let toyboxHeightTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/toybox_height.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    toyboxHeightTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let brickwallDiffuseTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/brickwall_diffuse.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    brickwallDiffuseTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let brickwallNormalTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/brickwall_normal.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    brickwallNormalTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let brickwallHeightTexture: GPUTexture;\n  {\n    const response = await fetch(\n      new URL(\n        '../../../assets/img/brickwall_height.png',\n        import.meta.url\n      ).toString()\n    );\n    const imageBitmap = await createImageBitmap(await response.blob());\n    brickwallHeightTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  // Create a sampler with linear filtering for smooth interpolation.\n  const sampler = device.createSampler({\n    magFilter: 'linear',\n    minFilter: 'linear',\n  });\n\n  const renderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        view: undefined, // Assigned later\n\n        clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n\n      depthClearValue: 1.0,\n      depthLoadOp: 'clear',\n      depthStoreOp: 'store',\n    },\n  };\n\n  const box = createMeshRenderable(\n    device,\n    createBoxMeshWithTangents(1.0, 1.0, 1.0)\n  );\n\n  // Uniform bindGroups and bindGroupLayout\n  const frameBGDescriptor = createBindGroupDescriptor(\n    [0, 1],\n    [\n      GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n      GPUShaderStage.FRAGMENT | GPUShaderStage.VERTEX,\n    ],\n    ['buffer', 'buffer'],\n    [{ type: 'uniform' }, { type: 'uniform' }],\n    [[{ buffer: uniformBuffer }, { buffer: mapMethodBuffer }]],\n    'Frame',\n    device\n  );\n\n  // Texture bindGroups and bindGroupLayout\n  const surfaceBGDescriptor = createBindGroupDescriptor(\n    [0, 1, 2, 3],\n    [GPUShaderStage.FRAGMENT],\n    ['sampler', 'texture', 'texture', 'texture'],\n    [\n      { type: 'filtering' },\n      { sampleType: 'float' },\n      { sampleType: 'float' },\n      { sampleType: 'float' },\n    ],\n    // Multiple bindgroups that accord to the layout defined above\n    [\n      [\n        sampler,\n        woodDiffuseTexture.createView(),\n        spiralNormalTexture.createView(),\n        spiralHeightTexture.createView(),\n      ],\n      [\n        sampler,\n        woodDiffuseTexture.createView(),\n        toyboxNormalTexture.createView(),\n        toyboxHeightTexture.createView(),\n      ],\n      [\n        sampler,\n        brickwallDiffuseTexture.createView(),\n        brickwallNormalTexture.createView(),\n        brickwallHeightTexture.createView(),\n      ],\n    ],\n    'Surface',\n    device\n  );\n\n  const aspect = canvas.width / canvas.height;\n  const projectionMatrix = mat4.perspective(\n    (2 * Math.PI) / 5,\n    aspect,\n    0.1,\n    10.0\n  ) as Float32Array;\n\n  function getViewMatrix() {\n    return mat4.lookAt(\n      [settings.cameraPosX, settings.cameraPosY, settings.cameraPosZ],\n      [0, 0, 0],\n      [0, 1, 0]\n    );\n  }\n\n  function getModelMatrix() {\n    const modelMatrix = mat4.create();\n    mat4.identity(modelMatrix);\n    const now = Date.now() / 1000;\n    mat4.rotateY(modelMatrix, now * -0.5, modelMatrix);\n    return modelMatrix;\n  }\n\n  // Change the model mapping type\n  const getMappingType = (): number => {\n    switch (settings['Bump Mode']) {\n      case 'Diffuse Texture':\n        return 0;\n      case 'Normal Texture':\n        return 1;\n      case 'Depth Texture':\n        return 2;\n      case 'Normal Map':\n        return 3;\n      case 'Parallax Scale':\n        return 4;\n      case 'Steep Parallax':\n        return 5;\n    }\n  };\n\n  const texturedCubePipeline = create3DRenderPipeline(\n    device,\n    'NormalMappingRender',\n    [frameBGDescriptor.bindGroupLayout, surfaceBGDescriptor.bindGroupLayout],\n    normalMapWGSL,\n    // Position,   normal       uv           tangent      bitangent\n    ['float32x3', 'float32x3', 'float32x2', 'float32x3', 'float32x3'],\n    normalMapWGSL,\n    presentationFormat,\n    true\n  );\n\n  let currentSurfaceBindGroup = 0;\n  const onChangeTexture = () => {\n    currentSurfaceBindGroup = TextureAtlas[settings.Texture];\n  };\n\n  gui.add(settings, 'Bump Mode', [\n    'Diffuse Texture',\n    'Normal Texture',\n    'Depth Texture',\n    'Normal Map',\n    'Parallax Scale',\n    'Steep Parallax',\n  ]);\n  gui\n    .add(settings, 'Texture', ['Spiral', 'Toybox', 'BrickWall'])\n    .onChange(onChangeTexture);\n  const lightFolder = gui.addFolder('Light');\n  const depthFolder = gui.addFolder('Depth');\n  lightFolder.add(settings, 'Reset Light').onChange(() => {\n    lightPosXController.setValue(1.7);\n    lightPosYController.setValue(0.7);\n    lightPosZController.setValue(-1.9);\n    lightIntensityController.setValue(0.02);\n  });\n  const lightPosXController = lightFolder\n    .add(settings, 'lightPosX', -5, 5)\n    .step(0.1);\n  const lightPosYController = lightFolder\n    .add(settings, 'lightPosY', -5, 5)\n    .step(0.1);\n  const lightPosZController = lightFolder\n    .add(settings, 'lightPosZ', -5, 5)\n    .step(0.1);\n  const lightIntensityController = lightFolder\n    .add(settings, 'lightIntensity', 0.0, 0.1)\n    .step(0.002);\n  depthFolder.add(settings, 'depthScale', 0.0, 0.1).step(0.01);\n  depthFolder.add(settings, 'depthLayers', 1, 32).step(1);\n\n  function frame() {\n    if (!pageState.active) return;\n\n    // Write to normal map shader\n    const viewMatrix = getViewMatrix();\n\n    const modelMatrix = getModelMatrix();\n\n    const matrices = new Float32Array([\n      ...projectionMatrix,\n      ...viewMatrix,\n      ...modelMatrix,\n    ]);\n\n    const mappingType = getMappingType();\n\n    device.queue.writeBuffer(\n      uniformBuffer,\n      0,\n      matrices.buffer,\n      matrices.byteOffset,\n      matrices.byteLength\n    );\n\n    device.queue.writeBuffer(\n      mapMethodBuffer,\n      0,\n      new Uint32Array([mappingType])\n    );\n\n    device.queue.writeBuffer(\n      mapMethodBuffer,\n      4,\n      new Float32Array([\n        settings.lightPosX,\n        settings.lightPosY,\n        settings.lightPosZ,\n        settings.lightIntensity,\n        settings.depthScale,\n        settings.depthLayers,\n      ])\n    );\n\n    renderPassDescriptor.colorAttachments[0].view = context\n      .getCurrentTexture()\n      .createView();\n\n    const commandEncoder = device.createCommandEncoder();\n    const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);\n    // Draw textured Cube\n    passEncoder.setPipeline(texturedCubePipeline);\n    passEncoder.setBindGroup(0, frameBGDescriptor.bindGroups[0]);\n    passEncoder.setBindGroup(\n      1,\n      surfaceBGDescriptor.bindGroups[currentSurfaceBindGroup]\n    );\n    passEncoder.setVertexBuffer(0, box.vertexBuffer);\n    passEncoder.setIndexBuffer(box.indexBuffer, 'uint16');\n    passEncoder.drawIndexed(box.indexCount);\n    passEncoder.end();\n    device.queue.submit([commandEncoder.finish()]);\n\n    requestAnimationFrame(frame);\n  }\n  requestAnimationFrame(frame);\n};\n\nconst NormalMapping: () => JSX.Element = () =>\n  makeSample({\n    name: 'Normal Mapping',\n    description:\n      'This example demonstrates multiple different methods that employ fragment shaders to achieve additional perceptual depth on the surface of a cube mesh. Demonstrated methods include normal mapping, parallax mapping, and steep parallax mapping.',\n    gui: true,\n    init,\n    sources: [\n      {\n        name: __filename.substring(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: './normalMap.wgsl',\n        contents: normalMapWGSL,\n        editable: true,\n      },\n      {\n        name: '../../meshes/box.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!../../meshes/box.ts').default,\n      },\n      {\n        name: '../../meshes/mesh.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!../../meshes/mesh.ts').default,\n      },\n      {\n        name: './utils.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!./utils.ts').default,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default NormalMapping;\n"},{name:"./normalMap.wgsl",contents:s,editable:!0},{name:"../../meshes/box.ts",contents:t(3583).Z},{name:"../../meshes/mesh.ts",contents:t(3150).Z},{name:"./utils.ts",contents:t(1146).Z}],filename:b});var T=S},9147:function(e){e.exports={canvasContainer:"SampleLayout_canvasContainer__zRR_l",sourceFileNav:"SampleLayout_sourceFileNav__ml48P",sourceFileContainer:"SampleLayout_sourceFileContainer__3s84x"}},3583:function(e,n){"use strict";n.Z="import { vec3 } from 'wgpu-matrix';\nimport { getMeshPosAtIndex, getMeshUVAtIndex, Mesh } from './mesh';\n\nexport interface BoxMesh extends Mesh {\n  vertices: Float32Array;\n  indices: Uint16Array | Uint32Array;\n  vertexStride: number;\n}\n\n//// Borrowed and simplified from https://github.com/mrdoob/three.js/blob/master/src/geometries/BoxGeometry.js\n//// Presumes vertex buffer alignment of verts, normals, and uvs\nconst createBoxGeometry = (\n  width = 1.0,\n  height = 1.0,\n  depth = 1.0,\n  widthSegments = 1.0,\n  heightSegments = 1.0,\n  depthSegments = 1.0\n) => {\n  widthSegments = Math.floor(widthSegments);\n  heightSegments = Math.floor(heightSegments);\n  depthSegments = Math.floor(depthSegments);\n\n  const indices = [];\n  const vertNormalUVBuffer = [];\n\n  let numVertices = 0;\n\n  const buildPlane = (\n    u: 0 | 1 | 2,\n    v: 0 | 1 | 2,\n    w: 0 | 1 | 2,\n    udir: -1 | 1,\n    vdir: -1 | 1,\n    planeWidth: number,\n    planeHeight: number,\n    planeDepth: number,\n    xSections: number,\n    ySections: number\n  ) => {\n    const segmentWidth = planeWidth / xSections;\n    const segmentHeight = planeHeight / ySections;\n\n    const widthHalf = planeWidth / 2;\n    const heightHalf = planeHeight / 2;\n    const depthHalf = planeDepth / 2;\n\n    const gridX1 = xSections + 1;\n    const gridY1 = ySections + 1;\n\n    let vertexCounter = 0;\n\n    const vertex = vec3.create();\n    const normal = vec3.create();\n    for (let iy = 0; iy < gridY1; iy++) {\n      const y = iy * segmentHeight - heightHalf;\n\n      for (let ix = 0; ix < gridX1; ix++) {\n        const x = ix * segmentWidth - widthHalf;\n\n        //Calculate plane vertices\n        vertex[u] = x * udir;\n        vertex[v] = y * vdir;\n        vertex[w] = depthHalf;\n        vertNormalUVBuffer.push(...vertex);\n\n        //Caclulate normal\n        normal[u] = 0;\n        normal[v] = 0;\n        normal[w] = planeDepth > 0 ? 1.0 : -1.0;\n        vertNormalUVBuffer.push(...normal);\n\n        //Calculate uvs\n        vertNormalUVBuffer.push(ix / xSections);\n        vertNormalUVBuffer.push(1 - iy / ySections);\n\n        vertexCounter += 1;\n      }\n    }\n\n    for (let iy = 0; iy < ySections; iy++) {\n      for (let ix = 0; ix < xSections; ix++) {\n        const a = numVertices + ix + gridX1 * iy;\n        const b = numVertices + ix + gridX1 * (iy + 1);\n        const c = numVertices + (ix + 1) + gridX1 * (iy + 1);\n        const d = numVertices + (ix + 1) + gridX1 * iy;\n\n        //Push vertex indices\n        //6 indices for each face\n        indices.push(a, b, d);\n        indices.push(b, c, d);\n\n        numVertices += vertexCounter;\n      }\n    }\n  };\n\n  //Side face\n  buildPlane(\n    2, //z\n    1, //y\n    0, //x\n    -1,\n    -1,\n    depth,\n    height,\n    width,\n    depthSegments,\n    heightSegments\n  );\n\n  //Side face\n  buildPlane(\n    2, //z\n    1, //y\n    0, //x\n    1,\n    -1,\n    depth,\n    height,\n    -width,\n    depthSegments,\n    heightSegments\n  );\n\n  //Bottom face\n  buildPlane(\n    0, //x\n    2, //z\n    1, //y\n    1,\n    1,\n    width,\n    depth,\n    height,\n    widthSegments,\n    depthSegments\n  );\n\n  //Top face\n  buildPlane(\n    0, //x\n    2, //z\n    1, //y\n    1,\n    -1,\n    width,\n    depth,\n    -height,\n    widthSegments,\n    depthSegments\n  );\n\n  //Side faces\n  buildPlane(\n    0, //x\n    1, //y\n    2, //z\n    1,\n    -1,\n    width,\n    height,\n    depth,\n    widthSegments,\n    heightSegments\n  );\n\n  //Side face\n  buildPlane(\n    0, //x\n    1, //y\n    2, //z\n    -1,\n    -1,\n    width,\n    height,\n    -depth,\n    widthSegments,\n    heightSegments\n  );\n\n  return {\n    vertices: vertNormalUVBuffer,\n    indices: indices,\n  };\n};\n\ntype IndexFormat = 'uint16' | 'uint32';\n\n// Box mesh code ported from threejs, with addition of indexFormat specifier for vertex pulling\nexport const createBoxMesh = (\n  width = 1.0,\n  height = 1.0,\n  depth = 1.0,\n  widthSegments = 1.0,\n  heightSegments = 1.0,\n  depthSegments = 1.0,\n  indexFormat: IndexFormat = 'uint16'\n): Mesh => {\n  const { vertices, indices } = createBoxGeometry(\n    width,\n    height,\n    depth,\n    widthSegments,\n    heightSegments,\n    depthSegments\n  );\n\n  const vertexStride = 8 * Float32Array.BYTES_PER_ELEMENT; //calculateVertexStride(vertexProperties);\n\n  const indicesArray =\n    indexFormat === 'uint16'\n      ? new Uint16Array(indices)\n      : new Uint32Array(indices);\n\n  return {\n    vertices: new Float32Array(vertices),\n    indices: indicesArray,\n    vertexStride: vertexStride,\n  };\n};\n\nexport const createBoxMeshWithTangents = (\n  width = 1.0,\n  height = 1.0,\n  depth = 1.0,\n  widthSegments = 1.0,\n  heightSegments = 1.0,\n  depthSegments = 1.0\n): Mesh => {\n  const mesh = createBoxMesh(\n    width,\n    height,\n    depth,\n    widthSegments,\n    heightSegments,\n    depthSegments\n  );\n\n  const originalStrideElements =\n    mesh.vertexStride / Float32Array.BYTES_PER_ELEMENT;\n\n  const vertexCount = mesh.vertices.length / originalStrideElements;\n\n  const tangents = new Array(vertexCount);\n  const bitangents = new Array(vertexCount);\n  const counts = new Array(vertexCount);\n  for (let i = 0; i < vertexCount; i++) {\n    tangents[i] = [0, 0, 0];\n    bitangents[i] = [0, 0, 0];\n    counts[i] = 0;\n  }\n\n  for (let i = 0; i < mesh.indices.length; i += 3) {\n    const [idx1, idx2, idx3] = [\n      mesh.indices[i],\n      mesh.indices[i + 1],\n      mesh.indices[i + 2],\n    ];\n\n    const [pos1, pos2, pos3] = [\n      getMeshPosAtIndex(mesh, idx1),\n      getMeshPosAtIndex(mesh, idx2),\n      getMeshPosAtIndex(mesh, idx3),\n    ];\n\n    const [uv1, uv2, uv3] = [\n      getMeshUVAtIndex(mesh, idx1),\n      getMeshUVAtIndex(mesh, idx2),\n      getMeshUVAtIndex(mesh, idx3),\n    ];\n\n    const edge1 = vec3.sub(pos2, pos1);\n    const edge2 = vec3.sub(pos3, pos1);\n    const deltaUV1 = vec3.sub(uv2, uv1);\n    const deltaUV2 = vec3.sub(uv3, uv1);\n\n    // Edge of a triangle moves in both u and v direction (2d)\n    // deltaU * tangent vector + deltav * bitangent\n    // Manipulating the data into matrices, we get an equation\n\n    const constantVal =\n      1.0 / (deltaUV1[0] * deltaUV2[1] - deltaUV1[1] * deltaUV2[0]);\n\n    const tangent = [\n      constantVal * (deltaUV2[1] * edge1[0] - deltaUV1[1] * edge2[0]),\n      constantVal * (deltaUV2[1] * edge1[1] - deltaUV1[1] * edge2[1]),\n      constantVal * (deltaUV2[1] * edge1[2] - deltaUV1[1] * edge2[2]),\n    ];\n\n    const bitangent = [\n      constantVal * (-deltaUV2[0] * edge1[0] + deltaUV1[0] * edge2[0]),\n      constantVal * (-deltaUV2[0] * edge1[1] + deltaUV1[0] * edge2[1]),\n      constantVal * (-deltaUV2[0] * edge1[2] + deltaUV1[0] * edge2[2]),\n    ];\n\n    //Accumulate tangents and bitangents\n    tangents[idx1] = vec3.add(tangents[idx1], tangent);\n    bitangents[idx1] = vec3.add(bitangents[idx1], bitangent);\n    tangents[idx2] = vec3.add(tangents[idx2], tangent);\n    bitangents[idx2] = vec3.add(bitangents[idx2], bitangent);\n    tangents[idx3] = vec3.add(tangents[idx3], tangent);\n    bitangents[idx3] = vec3.add(bitangents[idx3], bitangent);\n\n    //Increment index count\n    counts[idx1]++;\n    counts[idx2]++;\n    counts[idx3]++;\n  }\n\n  for (let i = 0; i < tangents.length; i++) {\n    tangents[i] = vec3.divScalar(tangents[i], counts[i]);\n    bitangents[i] = vec3.divScalar(bitangents[i], counts[i]);\n  }\n\n  const newStrideElements = 14;\n  const wTangentArray = new Float32Array(vertexCount * newStrideElements);\n\n  for (let i = 0; i < vertexCount; i++) {\n    //Copy original vertex data (pos, normal uv)\n    wTangentArray.set(\n      //Get the original vertex [8 elements] (3 ele pos, 3 ele normal, 2 ele uv)\n      mesh.vertices.subarray(\n        i * originalStrideElements,\n        (i + 1) * originalStrideElements\n      ),\n      //And put it at the proper location in the new array [14 bytes = 8 og + 6 empty]\n      i * newStrideElements\n    );\n    //For each vertex, place tangent after originalStride\n    wTangentArray.set(\n      tangents[i],\n      i * newStrideElements + originalStrideElements\n    );\n    //Place bitangent after 3 elements of tangent\n    wTangentArray.set(\n      bitangents[i],\n      i * newStrideElements + originalStrideElements + 3\n    );\n  }\n\n  return {\n    vertices: wTangentArray,\n    indices: mesh.indices,\n    vertexStride: mesh.vertexStride + Float32Array.BYTES_PER_ELEMENT * 3 * 2,\n  };\n};\n"},3150:function(e,n){"use strict";n.Z="import { vec3, vec2 } from 'wgpu-matrix';\n\n// Defines what to pass to pipeline to render mesh\nexport interface Renderable {\n  vertexBuffer: GPUBuffer;\n  indexBuffer: GPUBuffer;\n  indexCount: number;\n  bindGroup?: GPUBindGroup;\n}\n\nexport interface Mesh {\n  vertices: Float32Array;\n  indices: Uint16Array | Uint32Array;\n  vertexStride: number;\n}\n\n/**\n * @param {GPUDevice} device - A valid GPUDevice.\n * @param {Mesh} mesh - An indexed triangle-list mesh, containing its vertices, indices, and vertexStride (number of elements per vertex).\n * @param {boolean} storeVertices - A boolean flag indicating whether the vertexBuffer should be available to use as a storage buffer.\n * @returns {boolean} An object containing an array of bindGroups and the bindGroupLayout they implement.\n */\nexport const createMeshRenderable = (\n  device: GPUDevice,\n  mesh: Mesh,\n  storeVertices = false,\n  storeIndices = false\n): Renderable => {\n  // Define buffer usage\n  const vertexBufferUsage = storeVertices\n    ? GPUBufferUsage.VERTEX | GPUBufferUsage.STORAGE\n    : GPUBufferUsage.VERTEX;\n  const indexBufferUsage = storeIndices\n    ? GPUBufferUsage.INDEX | GPUBufferUsage.STORAGE\n    : GPUBufferUsage.INDEX;\n\n  // Create vertex and index buffers\n  const vertexBuffer = device.createBuffer({\n    size: mesh.vertices.byteLength,\n    usage: vertexBufferUsage,\n    mappedAtCreation: true,\n  });\n  new Float32Array(vertexBuffer.getMappedRange()).set(mesh.vertices);\n  vertexBuffer.unmap();\n\n  const indexBuffer = device.createBuffer({\n    size: mesh.indices.byteLength,\n    usage: indexBufferUsage,\n    mappedAtCreation: true,\n  });\n\n  // Determine whether index buffer is indices are in uint16 or uint32 format\n  if (\n    mesh.indices.byteLength ===\n    mesh.indices.length * Uint16Array.BYTES_PER_ELEMENT\n  ) {\n    new Uint16Array(indexBuffer.getMappedRange()).set(mesh.indices);\n  } else {\n    new Uint32Array(indexBuffer.getMappedRange()).set(mesh.indices);\n  }\n\n  indexBuffer.unmap();\n\n  return {\n    vertexBuffer,\n    indexBuffer,\n    indexCount: mesh.indices.length,\n  };\n};\n\nexport const getMeshPosAtIndex = (mesh: Mesh, index: number) => {\n  const arr = new Float32Array(\n    mesh.vertices.buffer,\n    index * mesh.vertexStride + 0,\n    3\n  );\n  return vec3.fromValues(arr[0], arr[1], arr[2]);\n};\n\nexport const getMeshNormalAtIndex = (mesh: Mesh, index: number) => {\n  const arr = new Float32Array(\n    mesh.vertices.buffer,\n    index * mesh.vertexStride + 3 * Float32Array.BYTES_PER_ELEMENT,\n    3\n  );\n  return vec3.fromValues(arr[0], arr[1], arr[2]);\n};\n\nexport const getMeshUVAtIndex = (mesh: Mesh, index: number) => {\n  const arr = new Float32Array(\n    mesh.vertices.buffer,\n    index * mesh.vertexStride + 6 * Float32Array.BYTES_PER_ELEMENT,\n    2\n  );\n  return vec2.fromValues(arr[0], arr[1]);\n};\n"},1146:function(e,n){"use strict";n.Z="type BindGroupBindingLayout =\n  | GPUBufferBindingLayout\n  | GPUTextureBindingLayout\n  | GPUSamplerBindingLayout\n  | GPUStorageTextureBindingLayout\n  | GPUExternalTextureBindingLayout;\n\nexport type BindGroupsObjectsAndLayout = {\n  bindGroups: GPUBindGroup[];\n  bindGroupLayout: GPUBindGroupLayout;\n};\n\ntype ResourceTypeName =\n  | 'buffer'\n  | 'texture'\n  | 'sampler'\n  | 'externalTexture'\n  | 'storageTexture';\n\n/**\n * @param {number[]} bindings - The binding value of each resource in the bind group.\n * @param {number[]} visibilities - The GPUShaderStage visibility of the resource at the corresponding index.\n * @param {ResourceTypeName[]} resourceTypes - The resourceType at the corresponding index.\n * @returns {BindGroupsObjectsAndLayout} An object containing an array of bindGroups and the bindGroupLayout they implement.\n */\nexport const createBindGroupDescriptor = (\n  bindings: number[],\n  visibilities: number[],\n  resourceTypes: ResourceTypeName[],\n  resourceLayouts: BindGroupBindingLayout[],\n  resources: GPUBindingResource[][],\n  label: string,\n  device: GPUDevice\n): BindGroupsObjectsAndLayout => {\n  // Create layout of each entry within a bindGroup\n  const layoutEntries: GPUBindGroupLayoutEntry[] = [];\n  for (let i = 0; i < bindings.length; i++) {\n    layoutEntries.push({\n      binding: bindings[i],\n      visibility: visibilities[i % visibilities.length],\n      [resourceTypes[i]]: resourceLayouts[i],\n    });\n  }\n\n  // Apply entry layouts to bindGroupLayout\n  const bindGroupLayout = device.createBindGroupLayout({\n    label: `${label}.bindGroupLayout`,\n    entries: layoutEntries,\n  });\n\n  // Create bindGroups that conform to the layout\n  const bindGroups: GPUBindGroup[] = [];\n  for (let i = 0; i < resources.length; i++) {\n    const groupEntries: GPUBindGroupEntry[] = [];\n    for (let j = 0; j < resources[0].length; j++) {\n      groupEntries.push({\n        binding: j,\n        resource: resources[i][j],\n      });\n    }\n    const newBindGroup = device.createBindGroup({\n      label: `${label}.bindGroup${i}`,\n      layout: bindGroupLayout,\n      entries: groupEntries,\n    });\n    bindGroups.push(newBindGroup);\n  }\n\n  return {\n    bindGroups,\n    bindGroupLayout,\n  };\n};\n\nexport type ShaderKeyInterface<T extends string[]> = {\n  [K in T[number]]: number;\n};\n\ninterface AttribAcc {\n  attributes: GPUVertexAttribute[];\n  arrayStride: number;\n}\n\n/**\n * @param {GPUVertexFormat} vf - A valid GPUVertexFormat, representing a per-vertex value that can be passed to the vertex shader.\n * @returns {number} The number of bytes present in the value to be passed.\n */\nexport const convertVertexFormatToBytes = (vf: GPUVertexFormat): number => {\n  const splitFormat = vf.split('x');\n  const bytesPerElement = parseInt(splitFormat[0].replace(/[^0-9]/g, '')) / 8;\n\n  const bytesPerVec =\n    bytesPerElement *\n    (splitFormat[1] !== undefined ? parseInt(splitFormat[1]) : 1);\n\n  return bytesPerVec;\n};\n\n/** Creates a GPUVertexBuffer Layout that maps to an interleaved vertex buffer.\n * @param {GPUVertexFormat[]} vertexFormats - An array of valid GPUVertexFormats.\n * @returns {GPUVertexBufferLayout} A GPUVertexBufferLayout representing an interleaved vertex buffer.\n */\nexport const createVBuffer = (\n  vertexFormats: GPUVertexFormat[]\n): GPUVertexBufferLayout => {\n  const initialValue: AttribAcc = { attributes: [], arrayStride: 0 };\n\n  const vertexBuffer = vertexFormats.reduce(\n    (acc: AttribAcc, curr: GPUVertexFormat, idx: number) => {\n      const newAttribute: GPUVertexAttribute = {\n        shaderLocation: idx,\n        offset: acc.arrayStride,\n        format: curr,\n      };\n      const nextOffset: number =\n        acc.arrayStride + convertVertexFormatToBytes(curr);\n\n      const retVal: AttribAcc = {\n        attributes: [...acc.attributes, newAttribute],\n        arrayStride: nextOffset,\n      };\n      return retVal;\n    },\n    initialValue\n  );\n\n  const layout: GPUVertexBufferLayout = {\n    arrayStride: vertexBuffer.arrayStride,\n    attributes: vertexBuffer.attributes,\n  };\n\n  return layout;\n};\n\nexport const create3DRenderPipeline = (\n  device: GPUDevice,\n  label: string,\n  bgLayouts: GPUBindGroupLayout[],\n  vertexShader: string,\n  vBufferFormats: GPUVertexFormat[],\n  fragmentShader: string,\n  presentationFormat: GPUTextureFormat,\n  depthTest = false,\n  topology: GPUPrimitiveTopology = 'triangle-list',\n  cullMode: GPUCullMode = 'back'\n) => {\n  const pipelineDescriptor: GPURenderPipelineDescriptor = {\n    label: `${label}.pipeline`,\n    layout: device.createPipelineLayout({\n      label: `${label}.pipelineLayout`,\n      bindGroupLayouts: bgLayouts,\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        label: `${label}.vertexShader`,\n        code: vertexShader,\n      }),\n      entryPoint: 'vertexMain',\n      buffers:\n        vBufferFormats.length !== 0 ? [createVBuffer(vBufferFormats)] : [],\n    },\n    fragment: {\n      module: device.createShaderModule({\n        label: `${label}.fragmentShader`,\n        code: fragmentShader,\n      }),\n      entryPoint: 'fragmentMain',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: topology,\n      cullMode: cullMode,\n    },\n  };\n  if (depthTest) {\n    pipelineDescriptor.depthStencil = {\n      depthCompare: 'less',\n      depthWriteEnabled: true,\n      format: 'depth24plus',\n    };\n  }\n  return device.createRenderPipeline(pipelineDescriptor);\n};\n\nexport const createTextureFromImage = (\n  device: GPUDevice,\n  bitmap: ImageBitmap\n) => {\n  const texture: GPUTexture = device.createTexture({\n    size: [bitmap.width, bitmap.height, 1],\n    format: 'rgba8unorm',\n    usage:\n      GPUTextureUsage.TEXTURE_BINDING |\n      GPUTextureUsage.COPY_DST |\n      GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n  device.queue.copyExternalImageToTexture(\n    { source: bitmap },\n    { texture: texture },\n    [bitmap.width, bitmap.height]\n  );\n  return texture;\n};\n"},7596:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/brickwall_diffuse.c9ee5359ababda94.png"},7669:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/brickwall_height.5e7f3bd0e5c45632.png"},4334:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/brickwall_normal.12f32d2510fd6264.png"},2146:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/spiral_height.0c894e7810776e93.png"},6465:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/spiral_normal.5cdc922342aadd02.png"},5784:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/toybox_height.826b323f99a3103b.png"},2283:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/toybox_normal.5758b42f35d39dd7.png"},3765:function(e,n,t){"use strict";e.exports=t.p+"static/assets/img/wood_diffuse.bfe4491cf7c50e45.png"}}]);